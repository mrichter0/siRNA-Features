{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cdca4e-d99b-4079-ac2c-616d42b1c630",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## MAKING STRUCTURAL PREDICTIONS WITH CHAI, mismatch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from chai_lab.chai1 import run_inference\n",
    "import os\n",
    "gpu_index = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_index\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"6\"\n",
    "\n",
    "\n",
    "example_fasta = f\"\"\"\n",
    ">protein|PIK3CB_AUAGGACUCAUAUUAGGAGAU_AUCUCCUAAUAUGAAUCCUAU_mismatch_guide_pos7\n",
    "MYSGAGPALAPPAPPPPIQGYAFKPPPRPDFGTSGRTIKLQANFFEMDIPKIDIYHYELDIKPEKCPRRVNREIVEHMVQHFKTQIFGDRKPVFDGRKNLYTAMPLPIGRDKVELEVTLPGEGKDRIFKVSIKWVSCVSLQALHDALSGRLPSVPFETIQALDVVMRHLPSMRYTPVGRSFFTASEGCSNPLGGGREVWFGFHQSVRPSLWKMMLNIDVSATAFYKAQPVIEFVCEVLDFKSIEEQQKPLTDSQRVKFTKEIKGLKVEITHCGQMKRKYRVCNVTRRPASHQTFPLQQESGQTVECTVAQYFKDRHKLVLRYPHLPCLQVGQEQKHTYLPLEVCNIVAGQRCIKKLTDNQTSTMIRATARSAPDRQEEISKLMRSADFNTDPYVREFGIMVKDEMTDVTGRVLQPPSILYGGRNKAIATPVQGVWDMRNKQFHTGIEIKVWAIACFAPQRQCTEVHLKSFTEQLRKISRDAGMPIQGQPCFCKYAQGADSVEPMFRHLKNTYAGLQLVVVILPGKTPVYAEVKRVGDTVLGMATQCVQMKNVQRTTPQTLSNLCLKINVKLGGVNNILLPQGRPPVFQQPVIFLGADVTHPPAGDGKKPSIAAVVGSMDAHPNRYCATVRVQQHRQEIIQDLAAMVRELLIQFYKSTRFKPTRIIFYRAGVSEGQFQQVLHHELLAIREACIKLEKDYQPGITFIVVQKRHHTRLFCTDKNERVGKSGNIPAGTTVDTKITHPTEFDFYLCSHAGIQGTSRPSHYHVLWDDNRFSSDELQILTYQLCHTYVRCTRSVSIPAPAYYAHLVAFRARYHLVDKEHDAAEGDHTDGQANGRDHQALAKAVQVHQDTLRTMYFA\n",
    ">rna|PIK3CB_AUAGGACUCAUAUUAGGAGAU_AUCUCCUAAUAUGAAUCCUAU_mismatch_guide_pos7\n",
    "AUAGGACUCAUAUUAGGAGAU\n",
    ">rna|PIK3CB_AUAGGACUCAUAUUAGGAGAU_AUCUCCUAAUAUGAAUCCUAU_mismatch_guide_pos7\n",
    "AUCUCCUAAUAUGAAUCCUAU \n",
    "\"\"\".strip()\n",
    "\n",
    "# Write the example FASTA to a file ### REQUIRED\n",
    "fasta_path = Path(\"example.fasta\")\n",
    "fasta_path.write_text(example_fasta)\n",
    "\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "output_cif_paths = run_inference(\n",
    "    fasta_file=fasta_path,\n",
    "    output_dir=output_dir,\n",
    "    num_trunk_recycles=3,\n",
    "    num_diffn_timesteps=200,\n",
    "    seed=42,\n",
    "    device=torch.device(\"cuda:0\"),  # Use \"cpu\" if no GPU is available\n",
    "    use_esm_embeddings=True,\n",
    ")\n",
    "\n",
    "\n",
    "pdb_files = list(output_dir.glob(\"*.pdb\"))\n",
    "print(\"Generated PDB files:\")\n",
    "for pdb_file in pdb_files:\n",
    "    print(pdb_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70251a6f-e41b-4277-9a02-4542624827d7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from chai_lab.chai1 import run_inference\n",
    "import os\n",
    "\n",
    "gpu_index = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_index\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"6\"\n",
    "\n",
    "sequence_file = Path(\"pik3cb_sequence.txt\")\n",
    "protein_sequence = sequence_file.read_text().strip()\n",
    "example_fasta = f\"\"\"\n",
    ">protein|PIK3CB_AUAGGACUCAUAUUAGGAGAU_AUCUCCUAAUAUGAAUCCUAU_mismatch_guide_pos7\n",
    "{protein_sequence}\n",
    ">rna|PIK3CB_AUAGGACUCAUAUUAGGAGAU_AUCUCCUAAUAUGAAUCCUAU_mismatch_guide_pos7\n",
    "AUAGGACUCAUAUUAGGAGAU\n",
    ">rna|PIK3CB_AUAGGACUCAUAUUAGGAGAU_AUCUCCUAAUAUGAAUCCUAU_mismatch_guide_pos7\n",
    "AUCUCCUAAUAUGAAUCCUAU\n",
    "\"\"\".strip()\n",
    "\n",
    "fasta_path = Path(\"example.fasta\")\n",
    "fasta_path.write_text(example_fasta)\n",
    "\n",
    "output_dir = Path(f\"output{gpu_index}\")\n",
    "output_cif_paths = run_inference(\n",
    "    fasta_file=fasta_path,\n",
    "    output_dir=output_dir,\n",
    "    num_trunk_recycles=3,\n",
    "    num_diffn_timesteps=200,\n",
    "    seed=42,\n",
    "    device=torch.device(f\"cuda:{gpu_index}\"),\n",
    "    use_esm_embeddings=True,\n",
    ")\n",
    "\n",
    "pdb_files = list(output_dir.glob(\"*.pdb\"))\n",
    "print(\"Generated PDB files:\")\n",
    "for pdb_file in pdb_files:\n",
    "    print(pdb_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f326d2b-4a40-4d06-a64e-d426c710391b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## MAKING STRUCTURAL PREDICTIONS WITH CHAI, mismatch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from chai_lab.chai1 import run_inference\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "gpu_index = 0  # Default to GPU index 0 if not specified\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_index)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"6\"\n",
    "print(f\"Using GPU index: {gpu_index}\")\n",
    "\n",
    "# Set the device directly with torch.device\n",
    "device = torch.device(f\"cuda:{gpu_index}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on device: {device}\")\n",
    "\n",
    "sequence_file = Path(\"pik3cb_sequence.txt\")\n",
    "protein_sequence = sequence_file.read_text().strip()\n",
    "print(f\"Loaded protein sequence from {sequence_file}\")\n",
    "\n",
    "df = pd.read_csv('gene_alignments2.csv')\n",
    "print(f\"Loaded CSV file with {len(df)} rows\")\n",
    "\n",
    "total_rows = len(df)\n",
    "portion_size = total_rows // 4  # Dividing into 4 parts\n",
    "start_idx = gpu_index * portion_size\n",
    "end_idx = start_idx + portion_size if gpu_index < 3 else total_rows  # Handle last portion\n",
    "df_gpu = df.iloc[start_idx:end_idx]  # Get portion of the file for this GPU\n",
    "\n",
    "print(f\"Processing rows {start_idx} to {end_idx} (total {len(df_gpu)} rows)\")\n",
    "\n",
    "for index, row in df_gpu.iterrows():\n",
    "    ensembl_id = row['ensembl_id']\n",
    "    target_rna = row['target_rna']\n",
    "    \n",
    "    print(f\"Processing ensembl_id: {ensembl_id}, target_rna: {target_rna}\")\n",
    "\n",
    "    example_fasta = f\"\"\">protein|PIK3CB\n",
    "{protein_sequence}\n",
    ">rna|AUAGGACUCAUAUUAGGAGAU\n",
    "AUAGGACUCAUAUUAGGAGAU\n",
    ">rna|PIK3CB_AUAGGACUCAUAUUAGGAGAU_{ensembl_id}_{target_rna}\n",
    "{target_rna}\"\"\"\n",
    "\n",
    "    fasta_path = Path(f\"{gpu_index}.fasta\")\n",
    "    fasta_path.write_text(example_fasta)\n",
    "    print(f\"FASTA file written to {fasta_path}\")\n",
    "\n",
    "    output_dir = Path(f\"output{gpu_index}\")\n",
    "    output_cif_paths = run_inference(\n",
    "        fasta_file=fasta_path,\n",
    "        output_dir=output_dir,\n",
    "        num_trunk_recycles=3,\n",
    "        num_diffn_timesteps=200,\n",
    "        seed=42,\n",
    "        device=device,\n",
    "        use_esm_embeddings=True,\n",
    "    )\n",
    "\n",
    "    cif_file = output_dir / \"pred.model_idx_0.cif\"\n",
    "    if cif_file.exists():\n",
    "        output_cifs_dir = Path(\"output_cifs\")\n",
    "        output_cifs_dir.mkdir(exist_ok=True)\n",
    "        new_cif_name = output_cifs_dir / f\"{ensembl_id}.cif\"\n",
    "        shutil.move(str(cif_file), str(new_cif_name))\n",
    "        print(f\"Moved {cif_file} to {new_cif_name}\")\n",
    "    else:\n",
    "        print(f\"File {cif_file} does not exist\")\n",
    "\n",
    "pdb_files = list(output_dir.glob(\"*.pdb\"))\n",
    "print(\"Generated PDB files:\")\n",
    "for pdb_file in pdb_files:\n",
    "    print(pdb_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c47bb-e610-42c0-b41c-effdef7a24c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "##OVERLAPPING\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from chai_lab.chai1 import run_inference\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    num_gpus = 1\n",
    "    gpu_index = 0\n",
    "\n",
    "    df = pd.read_csv('gene_alignments3.csv')\n",
    "    output_cifs_dir = Path(\"output_cifs_overlap\")\n",
    "    \n",
    "    # Filter out rows where the .cif file already exists\n",
    "    # df = df[~df['ensembl_id'].apply(lambda ensembl_id: (output_cifs_dir / f\"{ensembl_id}.cif\").exists())]\n",
    "    df = df[df['ensembl_id'] == 'ENSG00000005073']\n",
    "    total_rows = len(df)\n",
    "    portion_size = total_rows // num_gpus\n",
    "    \n",
    "    start_idx = gpu_index * portion_size\n",
    "    end_idx = (gpu_index + 1) * portion_size if gpu_index < (num_gpus - 1) else total_rows\n",
    "    df_gpu = df.iloc[start_idx:end_idx]\n",
    "\n",
    "    for index, row in df_gpu.iterrows():\n",
    "        ensembl_id = row['ensembl_id']\n",
    "        target_rna = row['target_rna']\n",
    "        \n",
    "        # cif_file = Path(f\"{output_cifs_dir}/{ensembl_id}.cif\")\n",
    "        # if cif_file.exists():\n",
    "        #     print(f\"Skipping {ensembl_id}, output file already exists: {cif_file}\")\n",
    "        #     continue\n",
    "        \n",
    "        print(f\"Processing ensembl_id: {ensembl_id}, target_rna: {target_rna}\")\n",
    "\n",
    "        example_fasta = f\"\"\">protein|PIK3CB\n",
    "MYSGAGPALAPPAPPPPIQGYAFKPPPRPDFGTSGRTIKLQANFFEMDIPKIDIYHYELDIKPEKCPRRVNREIVEHMVQHFKTQIFGDRKPVFDGRKNLYTAMPLPIGRDKVELEVTLPGEGKDRIFKVSIKWVSCVSLQALHDALSGRLPSVPFETIQALDVVMRHLPSMRYTPVGRSFFTASEGCSNPLGGGREVWFGFHQSVRPSLWKMMLNIDVSATAFYKAQPVIEFVCEVLDFKSIEEQQKPLTDSQRVKFTKEIKGLKVEITHCGQMKRKYRVCNVTRRPASHQTFPLQQESGQTVECTVAQYFKDRHKLVLRYPHLPCLQVGQEQKHTYLPLEVCNIVAGQRCIKKLTDNQTSTMIRATARSAPDRQEEISKLMRSADFNTDPYVREFGIMVKDEMTDVTGRVLQPPSILYGGRNKAIATPVQGVWDMRNKQFHTGIEIKVWAIACFAPQRQCTEVHLKSFTEQLRKISRDAGMPIQGQPCFCKYAQGADSVEPMFRHLKNTYAGLQLVVVILPGKTPVYAEVKRVGDTVLGMATQCVQMKNVQRTTPQTLSNLCLKINVKLGGVNNILLPQGRPPVFQQPVIFLGADVTHPPAGDGKKPSIAAVVGSMDAHPNRYCATVRVQQHRQEIIQDLAAMVRELLIQFYKSTRFKPTRIIFYRAGVSEGQFQQVLHHELLAIREACIKLEKDYQPGITFIVVQKRHHTRLFCTDKNERVGKSGNIPAGTTVDTKITHPTEFDFYLCSHAGIQGTSRPSHYHVLWDDNRFSSDELQILTYQLCHTYVRCTRSVSIPAPAYYAHLVAFRARYHLVDKEHDAAEGDHTDGQANGRDHQALAKAVQVHQDTLRTMYFA\n",
    ">rna|AUAGGAUUCAUAUUAGGAGAU\n",
    "AUAGGAUUCAUAUUAGGAGAU\n",
    ">rna|PIK3CB_AUAGGAUUCAUAUUAGGAGAU_{ensembl_id}_{target_rna}\n",
    "{target_rna}\"\"\"\n",
    "\n",
    "        fasta_path = Path(f\"fasta/{gpu_index}.fasta\")\n",
    "        fasta_path.write_text(example_fasta)\n",
    "        print(f\"FASTA file written to {fasta_path}\")\n",
    "\n",
    "        output_dir = Path(f\"outputdirs/output{gpu_index}\")\n",
    "        output_cif_paths = run_inference(\n",
    "            fasta_file=fasta_path,\n",
    "            output_dir=output_dir,\n",
    "            num_trunk_recycles=3,\n",
    "            num_diffn_timesteps=200,\n",
    "            seed=42,\n",
    "            device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "            use_esm_embeddings=True,\n",
    "        )\n",
    "\n",
    "        cif_file = output_dir / \"pred.model_idx_0.cif\"\n",
    "        if cif_file.exists():\n",
    "            new_cif_name = output_cifs_dir / f\"{ensembl_id}.cif\"\n",
    "            shutil.move(str(cif_file), str(new_cif_name))\n",
    "            print(f\"Moved {cif_file} to {new_cif_name}\")\n",
    "        else:\n",
    "            print(f\"File {cif_file} does not exist\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e39f45-e3d5-4696-9fc3-303784c34498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "375\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "num_gpus = 8\n",
    "gpu_index = 0\n",
    "df = pd.read_csv('gene_alignments3.csv')\n",
    "output_cifs_dir = Path(\"output_cifs_overlap\")\n",
    "with open('gna/errors.txt') as f1, open('amide/errors.txt') as f2:\n",
    "    errors1 = set(line.strip() for line in f1)\n",
    "    errors2 = set(line.strip() for line in f2)\n",
    "\n",
    "combined_errors = errors1.union(errors2)\n",
    "ensembl_ids = {Path(file).stem for file in combined_errors}\n",
    "df = df[df['ensembl_id'].isin(ensembl_ids)]\n",
    "print(len(df))\n",
    "df = df[~df['ensembl_id'].apply(lambda ensembl_id: (output_cifs_dir / f\"{ensembl_id}.cif\").exists())]\n",
    "total_rows = len(df)\n",
    "print(len(df))\n",
    "portion_size = total_rows // num_gpus\n",
    "\n",
    "start_idx = gpu_index * portion_size\n",
    "end_idx = (gpu_index + 1) * portion_size if gpu_index < (num_gpus - 1) else total_rows\n",
    "df_gpu = df.iloc[start_idx:end_idx]\n",
    "print(len(df_gpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "773665e6-84e6-42dc-b225-2801a0a155d5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n",
      "Missing entries in gna/errors.txt: {'ENSG00000005469.pdb', 'ENSG00000082898.pdb', 'ENSG00000081386.pdb', 'ENSG00000144036.pdb', 'ENSG00000064012.pdb', 'ENSG00000109321.pdb', 'ENSG00000069345.pdb', 'ENSG00000200795.pdb', 'ENSG00000228794.pdb', 'ENSG00000104880.pdb', 'ENSG00000144028.pdb', 'ENSG00000205730.pdb', 'ENSG00000236081.pdb', 'ENSG00000198626.pdb', 'ENSG00000138617.pdb', 'ENSG00000160959.pdb', 'ENSG00000198171.pdb', 'ENSG00000153933.pdb', 'ENSG00000166260.pdb', 'ENSG00000170917.pdb', 'ENSG00000140395.pdb', 'ENSG00000277972.pdb', 'ENSG00000023909.pdb', 'ENSG00000253352.pdb', 'ENSG00000115966.pdb', 'ENSG00000033627.pdb', 'ENSG00000138794.pdb', 'ENSG00000102362.pdb', 'ENSG00000152669.pdb', 'ENSG00000143373.pdb', 'ENSG00000139132.pdb', 'ENSG00000152404.pdb', 'ENSG00000163629.pdb', 'ENSG00000077157.pdb', 'ENSG00000156976.pdb', 'ENSG00000135775.pdb', 'ENSG00000169071.pdb', 'ENSG00000105649.pdb', 'ENSG00000172428.pdb', 'ENSG00000148346.pdb', 'ENSG00000136205.pdb', 'ENSG00000164022.pdb', 'ENSG00000161914.pdb', 'ENSG00000084090.pdb', 'ENSG00000154473.pdb', 'ENSG00000255150.pdb', 'ENSG00000099308.pdb', 'ENSG00000158710.pdb', 'ENSG00000196182.pdb', 'ENSG00000100348.pdb', 'ENSG00000242125.pdb', 'ENSG00000171303.pdb', 'ENSG00000147687.pdb', 'ENSG00000118515.pdb', 'ENSG00000097033.pdb', 'ENSG00000135766.pdb', 'ENSG00000182973.pdb', 'ENSG00000140545.pdb', 'ENSG00000135926.pdb', 'ENSG00000163624.pdb', 'ENSG00000135679.pdb', 'ENSG00000176046.pdb', 'ENSG00000108344.pdb', 'ENSG00000023171.pdb'}\n"
     ]
    }
   ],
   "source": [
    "## COMPARE ERROR FILES\n",
    "df = pd.read_csv('gna/errors.txt', header=None)\n",
    "df = df.drop_duplicates()\n",
    "remaining_entries = len(df)\n",
    "print(remaining_entries)\n",
    "\n",
    "with open('amide/errors.txt') as f:\n",
    "    errors = set(line.strip() for line in f)\n",
    "\n",
    "existing_entries = set(df[0].astype(str))\n",
    "missing_entries = errors - existing_entries\n",
    "\n",
    "if missing_entries:\n",
    "    print(\"Missing entries in gna/errors.txt:\", missing_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4170154-cadc-4684-ad5b-7e09c17e3753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting run_chai_mod.sh...\n",
      "Submitted batch job 89330\n",
      "Submitted run_chai_mod.sh successfully.\n",
      "Submitting run_chai_mod.sh...\n",
      "Submitted batch job 89331\n",
      "Submitted run_chai_mod.sh successfully.\n",
      "Submitting run_chai_mod.sh...\n",
      "Submitted batch job 89332\n",
      "Submitted run_chai_mod.sh successfully.\n",
      "Submitting run_chai_mod.sh...\n",
      "Submitted batch job 89333\n",
      "Submitted run_chai_mod.sh successfully.\n",
      "Submitting run_chai_mod.sh...\n",
      "Submitted batch job 89334\n",
      "Submitted run_chai_mod.sh successfully.\n",
      "Submitting run_chai_mod.sh...\n",
      "Submitted batch job 89335\n",
      "Submitted run_chai_mod.sh successfully.\n",
      "Submitting run_chai_mod.sh...\n",
      "Submitted batch job 89336\n",
      "Submitted run_chai_mod.sh successfully.\n",
      "Submitting run_chai_mod.sh...\n",
      "Submitted batch job 89337\n",
      "Submitted run_chai_mod.sh successfully.\n",
      "Script execution completed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "slurm_script_name = \"run_chai_mod.sh\"\n",
    "\n",
    "with open(\"run_chai.sh\", \"r\") as original_file:\n",
    "    lines = original_file.readlines()\n",
    "\n",
    "for i in range(8):\n",
    "    with open(slurm_script_name, \"w\") as modified_file:\n",
    "        modified_file.writelines(lines)\n",
    "        modified_file.write(f\"python run_chai3.py {i}\\n\")\n",
    "\n",
    "    try:\n",
    "        print(f\"Submitting {slurm_script_name}...\")\n",
    "        subprocess.run([\"sbatch\", slurm_script_name], check=True)\n",
    "        print(f\"Submitted {slurm_script_name} successfully.\")\n",
    "        time.sleep(10)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to submit {slurm_script_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "print(\"Script execution completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd4b48-4f06-458c-bef1-f1da383fe5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
