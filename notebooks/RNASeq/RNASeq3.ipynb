{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f2f039-a6ee-4468-ae27-ea3c1a960d06",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### GETS INFO ABOUT FIRST SEED MATCH\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Function to fetch sequences in batches\n",
    "def fetch_sequences_batch(ensembl_ids):\n",
    "    url = \"https://rest.ensembl.org/sequence/id\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"ids\": ensembl_ids}\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to convert only 'T' to 'U' in the DNA sequence\n",
    "def dna_to_rna(dna_sequence):\n",
    "    return dna_sequence.replace('T', 'U')\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Batch size and list of Ensembl IDs from the filtered DataFrame\n",
    "batch_size = 50\n",
    "ensembl_ids = list(df_filtered.index)\n",
    "region_length = 50\n",
    "\n",
    "for i in range(0, len(ensembl_ids), batch_size):\n",
    "    batch_ids = ensembl_ids[i:i + batch_size]\n",
    "    sequences = fetch_sequences_batch(batch_ids)\n",
    "    \n",
    "    if sequences:\n",
    "        for seq_info in sequences:\n",
    "            sequence = seq_info['seq']\n",
    "            ensembl_id = seq_info['id']\n",
    "            # Check if 'AATCCTAT' is in the sequence\n",
    "            if 'AATCCTAT' in sequence:\n",
    "                match_index = sequence.find('AATCCTAT')\n",
    "                # Extract region around the match\n",
    "                start = max(0, match_index - region_length)\n",
    "                end = min(len(sequence), match_index + len('AATCCTAT') + region_length)\n",
    "                \n",
    "                region_dna = sequence[start:end]\n",
    "                # Convert only 'T' to 'U' in the region\n",
    "                region_rna = dna_to_rna(region_dna)\n",
    "                sequence_rna = dna_to_rna(sequence)\n",
    "                \n",
    "                # Store the RNA sequence and other details in the DataFrame\n",
    "                df_filtered.loc[ensembl_id, 'region_around_match'] = region_rna\n",
    "                df_filtered.loc[ensembl_id, 'sequence_length'] = len(sequence)\n",
    "                \n",
    "                # Print the region converted to RNA\n",
    "                print(f\"Ensembl ID: {ensembl_id}\")\n",
    "                print(f\"Sequence Length: {len(sequence)}\")\n",
    "                print(f\"Region around match (DNA): {region_dna}\")\n",
    "                print(f\"Region around match (RNA): {region_rna}\")\n",
    "                print(f\"{sequence_rna}\")\n",
    "                \n",
    "                # Stop after one result\n",
    "                break\n",
    "    if 'region_around_match' in df_filtered.columns:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da2b5e-18dc-439e-bc35-9c52d7f2c1fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## MAKING STRUCTURAL PREDICTIONS WITH CHAI\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from chai_lab.chai1 import run_inference\n",
    "import os\n",
    "gpu_index = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_index\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"6\"\n",
    "\n",
    "\n",
    "example_fasta = f\"\"\"\n",
    ">protein|PIK3CB_AUAGGAUUCAUAUUAGGAGAU_AUCUCCUAAUAUGAAUCCUAU \n",
    "MYSGAGPALAPPAPPPPIQGYAFKPPPRPDFGTSGRTIKLQANFFEMDIPKIDIYHYELDIKPEKCPRRVNREIVEHMVQHFKTQIFGDRKPVFDGRKNLYTAMPLPIGRDKVELEVTLPGEGKDRIFKVSIKWVSCVSLQALHDALSGRLPSVPFETIQALDVVMRHLPSMRYTPVGRSFFTASEGCSNPLGGGREVWFGFHQSVRPSLWKMMLNIDVSATAFYKAQPVIEFVCEVLDFKSIEEQQKPLTDSQRVKFTKEIKGLKVEITHCGQMKRKYRVCNVTRRPASHQTFPLQQESGQTVECTVAQYFKDRHKLVLRYPHLPCLQVGQEQKHTYLPLEVCNIVAGQRCIKKLTDNQTSTMIRATARSAPDRQEEISKLMRSADFNTDPYVREFGIMVKDEMTDVTGRVLQPPSILYGGRNKAIATPVQGVWDMRNKQFHTGIEIKVWAIACFAPQRQCTEVHLKSFTEQLRKISRDAGMPIQGQPCFCKYAQGADSVEPMFRHLKNTYAGLQLVVVILPGKTPVYAEVKRVGDTVLGMATQCVQMKNVQRTTPQTLSNLCLKINVKLGGVNNILLPQGRPPVFQQPVIFLGADVTHPPAGDGKKPSIAAVVGSMDAHPNRYCATVRVQQHRQEIIQDLAAMVRELLIQFYKSTRFKPTRIIFYRAGVSEGQFQQVLHHELLAIREACIKLEKDYQPGITFIVVQKRHHTRLFCTDKNERVGKSGNIPAGTTVDTKITHPTEFDFYLCSHAGIQGTSRPSHYHVLWDDNRFSSDELQILTYQLCHTYVRCTRSVSIPAPAYYAHLVAFRARYHLVDKEHDAAEGDHTDGQANGRDHQALAKAVQVHQDTLRTMYFA\n",
    ">rna|PIK3CB_AUAGGAUUCAUAUUAGGAGAU_AUCUCCUAAUAUGAAUCCUAU \n",
    "AUAGGAUUCAUAUUAGGAGAU\n",
    ">rna|PIK3CB_AUAGGAUUCAUAUUAGGAGAU_AUCUCCUAAUAUGAAUCCUAU \n",
    "AUCUCCUAAUAUGAAUCCUAU \n",
    "\"\"\".strip()\n",
    "\n",
    "### ACCUCUGUUGUAGGACUAAUCCUAU\n",
    "### ACUGCGCUAGUGGACAGCCGAGCCCACCGCAGCCCACGAUUAGCACGCACGCGGUCCCCAGGCGCAGCUGUCCGUGCACGCCCAGCUCGGGCAGCACUAGCUGCCGGCUAUAGCGCAGAAUCUCAUCUCGGGACAGAGCGGCCUUCGGCGGCAGCGGCGACACCGGAACCAGCCGUUCUGGCUGCGGUUCCUGCUCAGCCAAAAGAGCCGACGCCAGCUUCUGCUUCAGCGAAUUCAAUUCCUCCUCACGUUGGGCAACUUCAGCUUGUAAGGCGAGUACCUCCUCCCGGGAAGCCAUGGCGACCUCUUCCGGAAGUUGUCGUGAAAGGCAUUUCCGCUUCCGUCUUCUGUCUCCUAGCGACUGGGAUAAACUAAAAAACUUUAUGGAGCUUGGGAAAAGGUGAUGAAUAGAUAUUUACUUCCUGAAGAAACCUUCAGAUUAAACUUCAAAGAUGUAUAAAUCCAGAAUAUUUCUAAUUGAACCACGCAAUGGCCCUAGAAGAACUAGCGAUCAAUCACACAGGUCAUCCCCCGCUUCCGAAUUUGGUACGGUCCGACCCGUCCUUUUCCGCGCCACAUUACGUAAUUCCGCUUCCGGCAUCUGGCUCAGUUCCGCCAUGGCCUCCUUGGAAGUCAGUCGUAGUCCUCGCAGGUCUCGGCGGGAGCUGGAAGUGCGCAGUCCACGACAGAACAAAUAUUCGGUGCUUUUACCUACCUACAACGAGCGCGAGAACCUGCCGCUCAUCGUGUGGCUGCUGGUGAAAAGCUUCUCCGAGAGGUAGCGCACCAGGUCUCCCUCCCCGAAGAAUGAGAUGAGCUGGCUUCCCCGGCCCGGGUGUCGGCAGCUGGCUGCGCGAAGCGGCCCUGUCCAGCCUUCUUUGCCUCACACAGGAAGGCCCGGGGAGAGGGCCACCCUGCGAGGGAAGCAGAGGCGGAUGCUUGUUGGGUUUUCUUCGUGUCCUGGGUUCUCAUUCCUGCCCUUGGGUUUUGUGAGACUCUCAUUUAUCUUUAUUAUGUAGUACUCCCGUCCCCCGCCUUUCCGUAGAAAGGUUGGCCACUCUUUUACUUGGAAGCGAGGCUGAAAGCGUGAUCCCACUCCUCCCUCUAGGCGGUCAGGAUCUGCGGCAAGAGCCGGGAGUCCAAGCGAGAGCUCUCACUCUCCGCUCCGGUGCCGAGUGCUUACAUAAGCAUGAGGUUUGGUGUGUGUGGGUUAGGGAGCUAUUGCUGGGCACGAUAACCUUUCUGGAAAGGAGAAAGCAGAAGAGCAUCUUCGCUGAUCACUGGUGGAUGUUUGGUGUGAUUGUUAGAACCGGGAUGGGGGGUGGGUGGAGUUCGAAUUUGGAAGUGUUAAUGCAGUGUUUUUAAAAACUGCAAAAAAUCCUGGAGUCAGUACGAAGUAACUUGUUUUACGAUUGCACAAAUGGGAUCAUGCUGUGAAAUCUUUGAAGACUUUUUCUCAUAUUAACAUGUACAAACAUAGCAAAUUACUUUGGAAGUUAGGUAACAUUCCAUAUGGCUGUGUUAUUUAUUUAAUCAGGUCAUGGCAAUGAACUGGAUUAUUUCCAGCGCCUUUUGGUUGUUUCUGUUUUUUGGCUUUUGCUUUGUCGAUGAGAACAAGGACUUUGUUCACACCAUAUUUUCCAGCUAAAUUUAGAAAAGUGCUUGACACAUAGCGGUGCUCCUUUAUUGCAUCAGUGUUGGCAGCAGACGCGUUCAUACUUUUACUUGUGUACUAGGGAUAAAUUCUUCGAGGUAGGAUUGCUGGGUCGACAGAAAUGUGCUUAAAAUGGACAGUUACUGCCAAAUUGCUCUAAAGAAAAAAAAGGUUGUACAAGUUUGGACUCUCCAUUCUUCAGAGUGCCUGUUUCCCUAUCAACCAGCCCGCCUGAGCAUUAGACUUAACAUUGUUGGAAGUACUCAUUUGUGAAAACCAUUGCUGUUUUGAUUGUAUUUCCUUGAAUAACUGCCUUCAUAUGCCUUGCCCCUCAGAGUUUUAAAAUUUUUAUUUUUCCUGUUUAAUCUUUUAAUUUUGAUUUCUAUAAGCUCUAAAUUAAAGAAAGUAACUAUCAUACAACCGAUCUCGUUCAGGGCUUGUAUUCUAAUUUUGCAAUUUUUUUUUUUGCUGUUUUAAUUUUUUUAUGUAGUACAAUUUAUGUUUCCUUUUAAUGGUUUGUGAAUCAAUCUUUUAAGAUCAAAAUGAAGUUUGAUAAAGGAAACAAAACUUUUCAGAUGCAAUCAAAUUACUUGAAGUCAGCCCAGCUUGGUACCUUUGAGCUGCCUCACCCUCAGGUGGUGUAGCUGCUUUGAAGUGGUAGGGGACAGUAAUUUGCUUUUAACGACCCCAUUUUGUUUAUGGAAUUUCUCUUUCAGCACGUCUAUUAAAAUCACCUUACAUAUUUUGGCAUGUAAAGGCACCAGUGCCCAGAUUUAAGGCACAGUGGGAAGCCAAAGUCAUUGUUCUACUCUUGGAGAAUAGAUAACACAGGGGUUUGCUUUCUUGUCUUCAAAGUUUGCUGGGGCUGACUUGUUAAAGCCUUUAACAGUGGAAUAUGUUUUCUGGUUGAUUUUCUUGUAUUUGUUUCUUUUUUCUUUUUCUUUUUUUUUUUUUUCUUUUGGAGACGGAGUCUUGCUCUGUUGCCCAGGCUGGAGUGCGGUGGCGCCAUCUUGGCUCACUGCAGGCCCCGCCUCCCGGGUUCUUUUUAGUAGAGACGGGGUUUCACUGUGUUAGCCAGGAUGGUCUCGAUAUCCUGACCUCGUGAUCCGCCUGCCUCGGCCUCCCAAAGUGCUGGGAUUACAGGUGUGAGCCACCGCGCCCAGCCUCUUGUAUUUGUUUCUUAAAGCAGGACCAAGAGAAAACGGAAUGUUAUGUCGUAGGUAUUAUUUAUCCACCAAGUAUUGUGUUGGUUUGUUUUUAGACUAGAAACUACCACCUGAGAUUAAUGGGAAGUAACAGAUGUUAAUUCUGAAGCACAGUGGAAUCUUUUGUAAUGCUACUCUGCUUUUGUUUUUUUAAUUUGAUAAUGUGAGGUAAUAGGCACAACUAUUUGAAAUUGUGGUUUAAGAUAAUGUCACCAUUCUAAAAUCGGUUUUUUUAAAGAUGAAAUUAAAUCAGAUUUAUACUUGAUUAUUCUAUUUGGAUCAGAUUAACAAGAAUAAUCACUGAGUUACUCAGUUUGGUUUGAGUUACCAUGUAAAGUACUUUUGAAAUAUUUUAUGUAACUAAGAUUUGCUAUUAAGGUUCAGAAUAUUAUUUCCAAAUAGGUAAUAAAAUUUCAUAUGGCUGGGCACGGAGGCUCAUGCCUGUAAUCCCAGCAUUUUGGGAGGCUGAGGCGGGCAGAUCACGAGGUCAGGAGAUUGAGACCAGGCUGGCUAACACGGUGAAACCCCGUCUCUACUAAAAAUACAAAAAAUUAGCCGGGCGUGGUGGUGGGCGCCUGUAGUCCCAGCUACUCCGGAGGCUGAGGCAGGAGAAUUGCUUGAGGCCAGGAGGCAGAGGUAAGCCGAGACUGCGCCACUGCAUUCCAGCCUGGCAACAGAGCAAGACUCCAUCUCAAAACAAAAAAAAUUCAUAUGAUACAUAGGUCAUUACGUGAUUUUCUUUUGAACUAAAAAGUUUGUUCUCUGUGUAGGAAUUCUUUAAUAUCUCAGGACAUUAGCAUGUUUCAGCAACAUACUGGGUUUGGAGGUAAAGUACUAAAUGUUUGACAUUUAUUUCAUUUGAUAAUUGAAGUUUUCCUCAACGAUUAAUAUAGCAAUACAUCUCCAUUUAUACUUUUAAGGAAUUAGUAAUUUUUAAAUUACUUUUAAAUUUGAGAACACUGUCAUCAGUCAUUAAUACAAAUUUAAUUUUUUUAGUGGAAUCAACUAUGAAAUUAUAAUCAUAGAUGAUGGAAGCCCAGAUGGAACAAGGGAUGUUGCUGAACAGUUGGAGAAGAUCUAUGGGUCAGACAGAAUUGUAAGUUAUAAGAACAUUUUUCUGUGAUAUGAAUUGUGAUUAUGUAGGGGAAAGAUGAGACAUGAACAAUGCUUAAAUUCAAUCUAUUUGUUUAGAAACUGAAAAGAUAAAGAGCAACUUACGCAUUUGGGAUUUAAAUGCAUUUUUGUUGUCCGUAAAAUUUUACAUAUCUUUGGUAUGUUGGGUCAGUGGUCAUUUUACAGCAAAGAGUGAGCUUUUGGAUGAACUCUGUUUAUAACUAAUUCUGCAGAUAAAUUUUCUUGAAGGGCAAAAAUUAAAGCAUGAUACUGAAUUGACAAGGAAUAUUAUAUAAUUGGGUUAUAAUUGGUAGUGUGUGUGUGUCUUAAUCUUUCUUGCUCCCUUUCGGUAAGUAUUCUCAUGCUUUCAUUAGAGAAUACUGCCUGAAAUUAAGAGCGUGUAGGUAGAAAAAGUUACUGUUUUCUUGUGAAACAUUAAUGACUUCUUAGAGUACUUGGCAUUUUUAGUCUAUAGAAUAGUCUUGUGAAAGUAGAUUGACUGUAUUAGUCCUAAACUUUAGAUUCACCCACUGUACCUUGAAACUUGUUAUUCUAAUAUAGAAGUUACUUAGGCAAAUAUAGAGUUUAUUUUAUAAUGGCUUCAUGAAUUUUAUUUUUGGUUACCGGUUUGUAUUUACAAAUGUUUAUGUAUACUCGAGCUCUUUUAUAAUUUAUAUUCACAAAUUAUUGCAGACCACAGUUUUUCAGUCUUGGCACUAUUGACGUGUGGACAGAUUAAUUCUUUACUGUGGGGGUUGUCGUGUUUAUUGUAGGAUGUUCAGCACCGCAUCUGGACUCUUCUCACUAGAUGCCACUAGAAACCCCCCUCCCCACUUGGCAACUGCAAAUGUUUGGAUAUUGUGAGAUAUUUCCUUAGGGGAAAAAUUACCCUUUGCCUCCAGUAGAGAACCAUUGGUAUAGAGAAAGAAGUCCCUUUGAGAACCUUUAUUGUUAUUUACAGUUCAAGAAAUGGUAAAUUAAUCAUUUUAAAAAAAAGCCACUCAGUCUAAAUAUUCUUGAUAAAUCUCAGUAAUAGAAAUACUUUCUACUUAGAGGUGAGUGUCAGUUGUAUGAGGUCUUGGUGGCAAGAGUUUAAAGGAACUGUGUUACUACAUGGUAAAUGUAGUUCUAGGAAUUCUUUCAGUCUGUCUCACAGAUGAGUAACUCAGGUCUGUCACACCUCAAGUCUUCUCUGAAAACCUUCUAAUGGAUGGGAAUACAGAAAGAGGUAAAAAGUUGACAAAUUUUCAGGCUUCUAGCAGAGACUUUCAGUAAUGCUAGGUUUGAAUUUUUGGCCAGUAGUUCCCUGUUUUCUUUAGAAGCCCAGGGUGAAGGCCACUGAUUCACAACACUUUUGAGUUAUGUGCUGCCAUUUAAUCUCGGACCAUCAACCAGACAACAUUUUGAAUACUUUUGUCAUAAAACCUCAGCCUUAGGAUGUGAUUGAUUGAUUUUAGGGAAUGGUUACUAAACUGACCUUUCAAAUUUUGGAACAACAUUGUCUUCAAAGACAUUUUUUCUAUCAACCCAAUAAAAUUCAAAAUGAGAAAAAAAGUUGCAUUCACUGUUACGAUUUCCCUCUACUACCAGAUAAAAUUCCUUAUUCAUUCAUUAUUUUAUGACAUUUAAAUAAGUUAAACUAGAAAAUGACUUUUAAAAAAAAACAGUAUUAAUCCAUGCUAGGGAUGACACUUGCUUUUAGUGACAGAUGUAUGUUUCGUUGAGAAAAUGAAGGAUAUUGAAACCAUGUUAGAAUACCUCAGAUAAAGUGUUCACCACAGAUGCUUUGUCAGCCUUUCAGACUGGCUGAAAUGAAUCUUUCAGAAAAGAAGCCAAAGAAGAUAUUUUUAAAAAUUCUGUAGGUGACACAACUGAAGCGAGAGGUUAGGUCAUUUUUAAUGACCUAACUAGGUAGGACCAUAGAGAAAUUGGGGGCACUUACUCUGAACUAUUCACAGUGCUUACAAGGCAGAGAUCUGAAAUUGUGAAGGACUUCAACUGCUCUGUGUUGAAUGCUUUUAUUAUGUUUGGUUUAUGUAGUUUGUUUCAUCUCCCAACUUGAGAUCAGAUAAAGUCAUUUAUAUUUUGUCAUAUUUUCUUCCAGCUUUAUUGAGGUAUAAUUGACAAAGUUAUAUAUAUUUAAAGUAUGAAUACCACAUUUGGGGAAUGAACCUGUCCAUCACCUCACGUAGUUACCCUUGGGGGCAAGUUGACAGUGAUGAGGACAGUUAAGAUCUGCUCUCUGUAAAUUUCAACUAUAUAAUAUGAUACUAUUAACUAUAGUCACCGUGCUGUGUGGUAGAUUCUUAGAACUUUGUCUUACAUUUUGUCAUUAUUUUAUAGUUUAGUAUUUUAAAAACUUACUCUGAUAAUAAAAUGUAACACGUUUAUUAUUCUUAAAACAUCAAAUGUAAGAUAAAAAGGUUUGACUACUUGAAAAUAUUAAACUUCUGUCCAUUCCUAAAUACCAAAAUAUUUCUAACAAGAUCAGUACCCCAACCAACCAGAUAAUUCAUAAGACCAAAACUAGAAAUGGCCAGUAAACAAGAAAAAAAUACUGAGCCUCACUGAUAAGUGAAGAUUUACAAAACAGGAGGAGAGUACAUAUUAGCCUUAUUAGCUGAAGAUUUAUUUUUAUUUUCUCCUUUCUUUUUAACCCAGUGUUUCUGAGAGUAUUAUAGAACAAGUCCACUCAAAUACUGUUGAUCCUAGUAUAAAUUGAUACUGUUUUUCUGAAGUAUCAUCUGGCAGUAAUCUCAUGACCCUCAAAAAUCCUUAAUGCCUUUGUAAUAAGUAUAAAGCAGUUUAUAAAACUGUAUAUGUACUAUAGUCUCAAUUCUGUUUUUAAGUAACUUUUUUCAAGAUUGUCUGUGAUAAGUUUUACAAAGGUUCUUGUCAAACAAAUUAUAGUUUCCCAUAAAAGUAUUUUAUAAGCAGCUGUGGCAAACAUGCUUCAAAAAGUAUAUGCCUGUCAUUCUUGCAAGCACUUUAUGUGAAUCCACUUGCUUGUUCCUCAUGAAAGCCAAGUGAGAGGGGGCUUUGUCACGCCUCUUUAUAUUCUCAAGAUCACAUGGCAAAUGAGUAGUGGCCAGGAUUCAAACCCAGGCAUUGUGGUUCCAGGGUUCAUCUUCCUGUCUGUAAUGCUAUCCUGCCUCACAUAGAAAGGGGCCAUCAGAUUGAUAUGAAGAGGCAAAAAAGGAUCAGGGGAGGGUGGAGAGGUGGAAUUAAGAGUCUGAAAGUAAAGCAUACCAAAUAGAAAUAGUUUGGAUUUCCUACAUAAGAAAUAAACAAGCACAUCCUUGUAAAAUAUAAAUGUUACCAGUAAAACCGAAGUUGCCUUUGAUGAACAUUUUAUUUAUUUAUUUAUUUAUUUUUUUUUUGAGAUUGGAGUCUCGCUCUGUCGCCCAGGCUGGAGUGCAAUGGCAAGAUCUCAGCUCACUGCACACUCUGCCUCCUGGGUUCAAGCAGUUCUCCUGCCCCAGCCUCCCGAGUAGCUGGGAUUACAGACCUGCACCACCAUGCUGGCUAAUUUUAGUAUUUUUAGUAGAGACUGGGCUUCACCGUGUUGGUCAGGCUCUUCUUGAACUCCUAACCUCAGGUGAUCUGCCCACCUCAGCCCCGCAAAGUGCUGGGAUUACAGGCGUGAGCCACCACGCCCGACCUGAUGAACAUUUUCUAUAGGCAUCCCAUUCCCUUGCACAGGGGAGACCCAGGUCAACAGUUUGGUGCGUUUUUUUGUGCAUAUAUGUGUGUAUGUGCAUUUGCAGAACUAGGUAGUGUGGUGGUCUUGUUUUUUAAAACAUAACUGCCAUCUUCCUGUAUCAUCAUUACUUCUAAUUCUGUCUUGGCGAUCUUUUGUCACCAGCUCACCUCAUUUCUGUUAAUGGCUCCAUAAUACUCUAAUAUUUUAUAUAAACCUUUGAAGAUUCUGAAAAUUAUAAGUAUCAUAGUCUCCUUGUCCAUGGUUUUGCUUUCCGUGAUUUGUUACCUGCAGUCUGAAAAGAGGUAAGUACAGUACAAGAAGAUUUUUUGAGUUAGACCAAGUUCACAUAACUUUUAUUACAAUAUAUUGUUGUAAUUGUUUUAUUUUAUUAUUGGGUAUUGUUAAUCUCUUACUGUGCUUAAUUUAUAAAUUAAACUGUGAUAGGUGUGUAUGUAUAAGAAAAAGUAUAUAUAAGGUUUGGUACUAUUGGAGAUUUCAGGCAUCUCCUGGGGGUCUUAGAAAGUAUCACUUGGGGUUAAGGGGGUGUGCAACUGUAACAAAGUUAUGUUUGUUUGUUUGUUUGUUUGUUUGUUUUUUGAGACGGAGUCUCACUGUGUCACUGAGGCUGGAGUGCUGUGGUGUGAUCUCAGCUCAUGCAACCUCUACUUCCCGGGUUCAAGCGAUUCUUCUACCUCAGCCUCCUGAGUAGCUGGGAUUACAGGCACGUGCCACUACACCUGGCUAAUUUUUGUAUUUUUAGUAGAGAUGAGGUCUCACCACGUUGGCCAAGCUGGUCUCUUAACUCCUGACCUCAAAUGAUUCACCCGCCUCAGCCUCCCAAAGUGCUGGGAUUACAGGUGUGAGCCACUGCAUCUGGCCAAAGUUAUCUUUUUUUAAAAGAAAGAUUUUCCAGCUAAAACAGAGUUGUAGAAAAUCUCAGAUGAGCUUUAAAAAAUUUGCUUUUUCAGGGCAGAUACCAGAUGGGGAUCAGUAUUUUGUCAGAAAUUAUUCACAAAAUCAAAUAAAAUCUAGCUGUGAUCUGAUAUAUCCUGCUCGAUUUUGUUCAGUGACUUGCAAUUAUCAUAGAUGCUUAUUUGAAUGUCUUUCCUUCCUGUAAGCUCUUACCAGACAGCAGUGUAUUUUAUCCAUCUUUAUGCAAGAUGUACUUUGCUAUAGAUACAAAUUGUGACUUAAAAUUUUUUAAAUGUGGGGAUAGUGGAGUAAAAGUGUAGAGGAUUUCUUUUUAGCAGUUAGAGUUAGAUUGUUAUCAGCUUAAAAUAGCCUGUUAUCACUAUAAGAUGGGUUUUGUAAGUCUCAUGGUAAUCAUAAAGGAAAAGCCUAAAGUAGAUUCACAAAAGAUAAAAAGUAAGGAAUCAAAGCAUAAUAGUACAGAAGAUAAUCAUAAAGGAAAGGAGAAAGAGAAAGAAGCAAAAGAUCUACAAAACAACUAGAAGCAAUUAACAAAAUGGCAGUAGGAAGUUCUUACAUUACAUGUCGGUAAUUACCUUGGAUAUAAAGGGAUUAAAUUCUCCAAAGACCUGGAGUGACUGAAUGGAUUUUUUAAAAAAGAGCCAACUAUAUGCUUCCCACAAAAGACUUGACUUGUAAGGAUACACAUAGACUCAAAGUGAAGGGAUGGAAAAAGACAUUCCAUGCAAAUAGAAACCUCCAGCAGAUUGCAUAUAGUGAAAAAAAAAAAAAAUCAUCUGCUUUAAUUGAAAAUGCUUUGUUGAGAGAUUUGCAGUCAGAGGCAACCUGCUUAUAUACUGGCAAGUGUAGAAGGGGACAAGAUAGACAAGACAUGCUCACUAAUGAGUCUCCCUGAACCCCAUACCUCAGAAACGUAGGGCACAGUGAGAACUUUGGCAUUUGACUUUUAAAGUGUCCAGCCAAAAGGAAAAACUAAACAAGUAAAAGUCAGGCUCCAACUAUUAAGCAAAAAGAUUUAGGAGGACUAAGUGAUUGACCAAUAGUAAGAAAAGAGAAAGAAUUUAAUUAGGAAUAUGACAUGUCCUUGGACCAGUAGAGGAGAUGAGGUCAUCCAAGCAUAAGGUCAAGAUAAGUUAAUAGAGGAAGAGUGAUAUUAGUAUUCAAAACCCAAAGGGAAUCGAGAGAACAAACAUCAGAUUUCCCAAGAAGGUGCAAAAUAAUGAAGUAAGUCCUACAUUUUUCUAGGAAGGAAUCAAUAGAUUUAAAAGGAAAAUCAAAUAUAGAUGUAAAGACAUAUUUAAAAUAGAGUGAGUGACACCAGAAAAAAAAGUUUAAAAUUGUGAUUGUAGGGUCAGGGUUAAAGAAUGUUGCUUUGCUGGACGGGCGCGGUGACUCAUGCCUGUAAUCCCAGUGCUUUGGGAGGCCGAGGCGGGCGGAUCACGAGGUCAGGAGAUCGAGACCAUCCUGGCUAACACGGUGGAACCCUGUCUCUACUAAAAAUACGAAAAUUAGCCGGGCAUGGUGGUGCAUGCCUGUAAUCCCAGCUACUCUGGAGGCUGAGGCAGGAGAAUCACUUUAACCCAGGAGGCAGAGGUUGCAGUGAGCGGAGAUCACGCCACUGUACUCCAGCCUAGGCAACAGAGCGAGACUGCAUCUCAAAAAAAAAAAAUGUUAGCUACGUUAAACUAUUUGGUUUGUUACCAAAUGCUUUUUUUUUUCUUUUGGCAAAAAAAUAUUAAGGAUACUUUGCUUUAAGUUCUAACAAGUGCAACUAUAUUUCUAUUAAAGUGAGUAUGCACUUUUGAAUAAGAUAAAAUUUAACAUGAUAAGAUUUCUGUUUCUGUGUGUAAAAUGCUAUUUCUUAUUCCUACAGCUUCUAAGACCACGAGAGAAAAAGUUGGGACUAGGUAAGUCGUGUAAUCUCUAACCCCUCACACCUGCUGCUUGCUUGGUGACAUGAUCCAGUGUGUAUUUUCCCAGUUUGGAAUAGGGCCAAAAUACAGUAACUUCCUAUGAUGGUUUUUAAUGAUCUUAAUGACAUUUAAAUGGUAUAACUUGGGUCGCCUGUAUAAGUCAAGACCCACUCAGGAAAACAGAACCACUGUAAGUCUUUCAGUGUAGGGAAUUUAAUACUGAGUCUCUGGUUACACCCCUGAAGGAGUUCCUGAGAAACCAAAUGGAGCAGUGAGGCUACUAAGAUUAGUAACAGCUGGAGGUCACUGCCACCCCUAGGGAUGGAGCAACGGCAGGAAGAGAUGUUAGAGCCCAAGAACCUGGGCUGCCCAGAGGGAGCUAGAAUGAUGGGGCAGGGGCUGCCUGGCAGGAGCUAGAACUGUGGGAAAUUCCCAGUCAGAGGUAGGAGGGAGAGUAACAGAGGGAGGACCACUUAGACUUUUCCCUUUUCCCCUCCCUGCAGUCUUCCACCUGUACCUCCCAAAGCUGUUUGGCAGCCAGUUGACAAGAGAAUCUGGAAUAUGUAGUUCACCCAAUAUAGCACAGAGUAGGGAAGGGCCAGAGAAUGGGUCUGAGGGCAAAUAUCUUGGACCAGCAUGCUGCAAACCUUGGAACAUCCUUUAAGUUACAAGUUUAAAAAGUUACUCUUCAUUUAAGGCUGGGCACAGUGGCUCACAAAUGUAAUCUUAGCACUUUGGGAGGCCGAGGUGGGCAGAGCACGAGGUCAAGAGAUCGAGACCAUCCUGGCCAACAUGGUAAAACCCCAUCCCUACUAAAAAUACAAAAAUUAGCUGGGCGUCGUGACGCGCAUCUAUAAUCCCAGCUACUCGGGAGGCUGAGGCAGGAGAGUCGCUUGAACUCAGGAGGCAGAGGUUGCAAUGAGCCGAGAUCACACCACUGCACUCCAGCCUAGUGAUAAAAACAGUUAUUCUUUAUUUUUAAAAAAGGAAGCUUUUCCAGCUUUUAAACAUACAGCAUUAUUGAAAAGCUCAUAUGAGCUCAGUAAUUCUGAGAGGAAACUCUGCCUUUAUUUGUGCUAAAACUUAACAUGAAGAAAGCACAAUGCUUAACUGGAGUCUGCUAUCUUGAAGACCAUCAAUUCCCAAGCAUCAAAUGUUCUCAGUAUCUGAACCCAGAAGAUUCUUUGGGAUUCAAAAAAAUCUGGAAACUGCCAUGAAACCAAAAAGUGUAAAUAUUCACUCCUUUAUCUUUCUGAGACAGUCUUACUCUGAUCCCCAGGCUGGAGUGCAGUGGCACAAUCUCGGCUCACUGCAACCCCUGCCUGCUGGGUUUGAGCCAUUCUUGUGCCUCAGCCUCCCGAGUAGCUGGGAUUACAGGCGUGUACCACCAUGCCCGGCUAAUUUUUGUUUGUUUGAGACGGAGUUUCGCUCUUCUUGCCCAGGCUGGGGUGCGAUGACGCGAUCUCGGCUCACCGCGAUCUCUGCCUCCCGGGUUCAAGCGAUUCUCCUGCCUCAGCCUCCCAGGUAGCUGGGAUUGUAGGCAUGCACCACCAUGCCCAGCUAAUUUUGUAUUUUUGGUAGAGACGGGGUUUCUCCAUGUUGGUCAGGCUGGUCUCGAAUUCCCGACCUCAGAUGAUCCGCCUGCCUCGGCCUCCCAAAGUGCUGGGAUUACAAGCGUGAGCCACUGCGCCUGGCCAAUUUUUUGUAUUUUUAGUAGAGAUGAGGUUUUGCCAUGUUGGUUAGGCUAGUCUCAAACUCCCUGACCUCCAGUGAUCCACCCAUCUCAGCCUCCCAAAGUGCUGGGAUUACAGGCAUGAGCCACCACACCCAGCCGAUAUUCACUUCUUAACAAAAUAAGUUAGAAGAGUUCAGCCUUGCUCAUAAGACACUUGUGAGGGGUCUGGACUAGAGAAUGCAGGAAUCCCCAAGUCCUGCUCCUAACAAGUUACCCUAGCCUGCCAAGUCCCUGUGGGACUUUGAGGCAUGGAGCUGGCUGAGUAAUUGUCACCUAGGCCUUUGGCCCCAAAUACCAGAGCAAGGGUCUAGCGUACCAGGUUUACGGUGUAAAAGACAAGAAAAAGGGAAUUGAAAUGUUUUGGAUGGAGAAUCAAUAGGACUUAAUUACAGUUUAGAAGUUAUGGUUAAAGGCAGGAAAUCAAGAAUCAUCUCUAGACCUGUGGAUGGAGCAGUUGGAUAGUUGGUGCCUUUCCUGGAGAGGUGGCCUGUAAGAGAGAGGUAGAGAAUUGGAAGAUGAUUUUGCAAUGUUAUCUUUGAGAUUUCUGAAAUACCCAAGUGGAGAUAUUAAGUAGGAAGCUGAUUUGUAAAUGUGGAGCUCAUCAGUGUCUUAGGGGGAUGCCAAGGAAACACCAGAUGGGUUUUUAAAGCAUGAGAAUGUGAUAAUUGUGCUACAUAAUCUUAGACUUUUGAACUUAUAAACUAUUUCUUUGCUAUACUGAAAUAGAGGUAUGAUCUAUUGUAUUAAAUUGACAUCUGAAUGGGGGUGUGUGGCCAGCUACCUUCUUGAUUAUAUAUGUAAUAUACAUGAACUUAUGUACUUAAGGUGAAAAAUACCAAUUUAUUAAUCUGACUUUUAGAGAACUAAUGUGUGCUCUUCAGGUGCUAAACAAUUUCCUUGAUGUUCAAAUGUAUAUGUAAAGAUUUCUGUUGAUUUUCUUGAAUGGAUCUACUUUCAUUUUUAGGAACUGCAUAUAUUCAUGGAAUGAAACAUGCCACAGGAAACUACAUCAUUAUUAUGGAUGCUGAUCUCUCACACCAUGUAAGUGGUAUGUUUCUUUAUUAGCUAUUUAUGGUAGUCUUAGCCUGUUUUACUGACUUACUGUUUAUUCUUUUCAAAUUUCAGCCAAAAUUUAUUCCUGAAUUUAUUAGGUAGGUACUAUUUCUAAUAUUUGAAAGAAAUAUGACUGGAAACAUUUAUCUUACUGGUUUUGGGCUUAUUUUCAUUUUUUAUUAAUCAAAAAUACACAUACUAUUUUUUCUAUCAAAAAUAUAAACAAAGUUUGGGAAGUCAGGGUAGGAGGGUUGCUUGAAGUCAGCAGUUUGAGACCAGCCUGGGCAACAAAACAAGUACUUGUCUCUACAAAAAAAAUAACAAAAAUUAGCCAGACACAAUGGCAUGCGCCUGUAGUCCCAGCUACUCAGGCGGCUCAGGUGGGAGGAUGACAUGAGCCCAGGACUUCAAGGCUGCAGUGAGCUAUGAUCAUGCCUCUCCAUUCUAGUCUUGGUGACCCUGAGACAGAGUGAGACCUUGUCUCUAAAAUAUUUAUCUGUAUAGAUAGUAGACACACACACACACACACACACACACACACACACACACAACACACAUUUGAGACUAAAUGAUGUAUUUUAGGAGUCCUGAGGAGCAAAUCAACAGGUAGUUCGUUAUCUGAAUUCUUUCAGACCACAGAAAAAGGUGGAAGAUGGCUUCUCUGAUAAAUGGAAUUAAGCCUUGAGUUAUUAGAAUAAAACACCGUGAACAAAAGGGUUUAUUCCAGGAAUGCCAGAAUGGCUCAUUAUUGGUAAUCACUUAUAAUUCAUUCAUUAUGUUAACAAAGUAGUGUGGUUAAGUCUGUAGAUGCUAAAGGAGAUAUUAUUUACUACCAUUUUCUAGUUAAAACUUUAAGAAUAGAAGGAAACCUCUUAAGCAUAAUAAAAAUAACCCAGUCCUAAUACAAAUACCACACCAAAUAGUGAAAUGCUGAAUCAUUUCCAAUACAUGCAUUAAUACAGGCAUGCUAGCUAUCAUUAAACAUGGAAAUGUUAAUACAGUAAGAUAAGAAUUUAGUUAAAUGUUAGUAAAAUAUACACAGUUAUAUUUGUUUGUAGGCAAUAUAAUUAAAUUCUUAGCCCAAAAGACCACAAAACCUCUGUGAAUAAGAUUUUGGAAGCUGUUCUGAGUUUAAGCUAGAUACAUAAAAACAGAAUCAGAUUAUUGUCCCUCCAGUUCAGGGAGUUCAGGGAGUUCCCACUAACAUCUAGGGAAAAAUCCAAGUUCCUUCCCUUGUCCCUCAAGCCCCUAUGUGUUUGUUGGCCCCUGCCUCCCUUUCUGACCUCUGCCUUGUGCUCCUUCCUUUUUGCUUUCCAUGCCAUAGCAUGCUUCUGAGUUCACAGAGUUCCAUUUUCCUUUGCCUGAAAUGCUGUUUCCAUGCUCCUUGAUGACCAUCUGCUGCUCAUCCUUCAAUCUCUGCGUAAAGUCACCUUAGACCUUUUUUGGUUAUAUCUCCAGUAUACAAAAGCCUCUUUAACCUGUAGAGUAGAAAAUGGGCAAAAAGAUACAAACAGACCAUCUAUAGAAGAAAUCCAAAUGGCUAAUAAAAGAAGACGUUCUUCCUGGGAUGUAGUCAAGGAAAUAAACACAAAAUAACUGUGUGUGACCAUUUUAUUAUCCAUUAGUUUAACAAAGUUAAAAACUUUUAGAGCAGUAGUAAUAUCCAGUACCAAUAAGAUGGUAAAAAAUGGACACACAAAUAUUGCUGAAGGAAGUAUAAGUUGCUAUAACCCUUUUGGAAAAUAUGUGUUCAAAUUUGGGAAAAUAUGUGUUAGAAUUAAAAAUACUCAGGCUUGGCCGGGCGCAGUGGCUCACGCCUGUAAUCCCAGCACUUUGGGGGGCCGAGGCGGGCGGAUCACGAGGUCAGGAGAUCGAGACCAUCCUGGUGAACACGGUGAAACCCUGUCUCUACUAAAAAUACAAAAAAAUUAGCCAGGCAUGGUGGUGUGCACCUGUAGUCCCAGCUACUCGGGAGGCUGAGGCAGGAGAAUGGCAUGAACCUGGGAGGCGGAGCUUGCAGUGAGCCAAGAUCGCGCCACUGCACUCCAGCCUGGGCGACAGAGCGAGACUCCAUCUCAAAAAAAAAAAAAAAAAUACUCAGGCUUCAUUUGGGCAAUUCCAGUAUAUUCCAUUUUGGGGAGUCUAAGCAGUAAUACAUUUAUAAAAACGUUUAUUGUGGCCAGGCACAGUGGCUCAUGCCUGUAAUCCCACACUUUGGGAGGCUGAGGCGGGCGGAUCAUGAGGUCAAGAGAUUGAGAGCAUCCUGGCCAACAUGGUGAAACCCCGUCCCUACUAGAAAUACAAAAAAUUAGCCGGGCAUGAUGGCACUCGCCUGUAGUCCUAGCUACUUGGGAGGCUGAGGCAGGAGAAUCACUUGAACCCGGGAGGUGGAGGUUGCAGUGAGCCGAGAUGGCGCCAUUGCACUCCACCCUGGCAACAGAGCGAGACUCCAUCUCAAAAAAAAACAAAACAAAACAAAAAAAGUUUAUUGUAGCACUGUUUAUUGUGGUUGAGAGGGUAGGGCACCAUGGAAACAACCACAGAGGUGUGUGAGUUGAAUAUUCUAUGAAGUAGUUUUGCAAUUAUUAAAAAGAAUGGGAAAGAGCUCUCUUGACCUGUAGGGAUGUCUAUGAUUCCAUGAUUUGCAUUGUUUUUGUUUUGAGAUGGAAUCUCACUCUGUCAUGCAGGCUGGAGUGCAGUGGCGCAGUCUCAGUCACUGCAACCUCCACGUCCCGGGUUCAAGCAGUUCUCCUGCCUCAGCCUCCAGAGGAGCUGGGAAUACAGGCACGUGCCACUACACCUGGCUAAUUUUUGUAUUUUUAGUAGAGACAGUUUCACUGUGUUGGCCAGGCUAGUCACAAACUCCUGACCUCAAGUGAUCCACCUGCCUAGGCCUCCCAAAGUGCUGGGAUUACAGGCGUGUGCCACCACAUCUGACCCCAUGAUAUGUAUUGUUAACUGACAGAAACCAGGUCACAAAAUGUACUUUUUUUGCAUCCCAAUUUUGUAAAUGCAACCAAAAAUCCUAGGGGUGUAUGUUUGUCUUUAUCUUUCUCUAGGCAAAGAAAAGUGUGGCAGGACAUCAGGCUGUUUUUAGUAUUAUUUGCUUCAAAGAAGGCAAGAACAGAAUGGAAGGGUAUUGGGAAAAUUAAUUAUUUUAAUUUGAGAGACAAGGUCUUCCAUUGUCACCCAGGCUGGAGUACAGUGGCACAAUCACAGAUCACUGCAGCCUGAACCUCCCUGGCUCAAGCCAUCCUCCCAUUGCAGCCUCCCAAAUAGCUGAGACUAAAGGCAUGUGCCACUGUGCCCGACUAAUUUUUUUUUUUUUUUUGAGAUGGAGUCUCACUCUUGUUGCCCAGGCUAGAGUGCAGUGGCGUGAUCUCAGCUCACUGCAACCUGCCUCCUGGGUUCAAGUGAUUCUCUGCCUCAGCCUCCUGAGUAGCUGGGAUUACAGGCACCCGCCACCGCGCCAGGCUAAUUUUUAUAUUUUUAGUAGAGAUGGGGUUCCACCAUCUUGGCCAGGCUGGUCUUGAACUCCUGGCCUCGUGAUCCACCCGCCUCGGCCUCCCAAAGUGCUAGGAUUGCAGGCGUGAGCCACUGCACCCAGCCUGUGUCGACUUCUCUUAAAAGUUUUGUUUGUGUAGCUCAUGAAAAUGACUGUUGAAAGCUCAGUGGCUUUUUCUAAUUGACAGCUAAUUUAUUCUACAGGAAGCAAAAGGAGGGUAAUUUUGAUAUUGUCUCUGGAACUCGCUACAAAGGAAAUGGAGGUGUAUAUGGCUGGGAUUUGAAAAGAAAAAUAAUCAGGUAGGUACAUGUGUUACAACUUCUUUAUUAGUAUAACUACUGGAAAUGUAUUCAUAGCAAGUAUUUGGAUUAGCUAUCAUGCUGCCCGGGAUUUGUGGGAUCAGGUUAUAACUUCCAGUAAAUACUCCCAGAUAGUUUCUUACAGUUUUUCCUGUGAUUAGAGCCUGGAUGUUUUUUAUUAAGGAAAAAUCAGCAUAAACCUUUGGACCUUUGGUAGAAAUGGUCUCAUUCAGCAAAAGUUACUGUACUGGACCUUCAGUUUUAAUUUAUGUGACCUGUUCUAUACUUUUGGUCUAAAUAUGUAGGGUUUCUCCCCAUAAUUAUAGUGUAAUUUUAAUUAAGAUUGAUUUCAGACAGACCUGGGUUAAAGUCUUAACUCACUGCAACCUCUGCCUCCCGGGCUCAAGCAAUUCUCCUGUCUCAGCCUCCCGAGUAGCUGGGACUGUGGACCUGCACCACCAUGCCUGGCUAAUUUUUGUUUCAUAGAGAUGGGGUUUCACCAUGUGGCCCAGGUUGCCCUCGAACUCCUGAGCUCAGGUGAUCUGCCUGCCUCAGCUUCCCAGUAGCUGGGACUGCAGGCACGUACCACCAUGCCCAGCUAAUAUAUAUAAUAUGAAUAUAUAUAUAUAAUAUGAAUAUAUAUAUGAAUAUAUAUAAUAUGAAUAUAUAUGUAUAUGAAUAUAUAUAAUACGAAUAUAUAUGAAUAUAUAAUAUGAAUAUACAUAUUAUAUGAAUGUGUAUAUAUAUUAUAUGAAUGUAUUUUAUUUAUAUAUAUAUAUAUAUAUAUAUAUAUAUAUAUAUAUUCACUUUUUUUUUUGUAGUGAUGGAGUUUUGCCAUGUUGCCCAGGCUGGUCACUCCUGGGCUCAAGUGAUCCAGCCAUCUUGGCCUCCUGGGAUUACAGGUGUGAGCCACCGCGCCUAGCCAGGUCUCCUUUCAUUGACUAAAAAUUUCUAUUUUGUUCUAGAUAAAUAACAUUUUUAUGAAAUUAAUGUUACAUUUAUGAAAUUAGUAUAGCAUUUUAACACUGUUCUUCGAUGUGUUUCUCUUGUUUAUAAAUUGUAUUUUGUAAAGAAGAUCUGAUUGUUUUAUUUGGCAGCCGUGGGGCCAAUUUUUUAACUCAGAUCUUGCUGAGACCAGGAGCAUCUGAUUUAACAGGAAGUUUCAGGUACAGUGAAAAUUUCCACUACUUUUAUAUAACUUCUUGGCUAACUUUCUUUACAAUGGAUAUUUUAAAGAGACACUUUACAUUUCUACCUUGUUUUUAUUCUGGGAUACUAAAAAGGCAGACUAAAAUUCCUAGAAGUUGCUAAUGAAGCCUAAACAUCUCAAGGAGACAUAUUGUGCUUUUCCUUUAAAAAGCUGAAGGCAGUUAGGUUUGUGUGCUUGUUAACAUUAGUAUUAAGGCUCAACUGCUCUUUGGAAUGUUGCUAUUACUGAUAAUCUGUUCCAAAGAAUAGCAUGUACUUAAUUUUCUGCAUUUCAUAUGAAUACCUACAGCAUUGUCUACAGAAAAGGUUAAACUCUUUAAUAUUUAUAUAGAGCUCUCUCAGUUACCUUGUUCUCCAUAUGUUUGAGGAAAUUUUUGUUGUUCAAUUUGGACAAAGCUUCGGUCCCUCUGAGUUUUGCGUGUCUGUUUCUGGGUGUAUGGGGUGGUGGUCUAGAUUUGCUGUAGUAGAUGUGAGCUGCUUUGUGUGACUGACCAUGGCAAAUGACAAAACUUGCCAGAUUUUUUUUUUUAAUCUCUGAAACUAUAAAAUGCCCCUGCAUCUACUUUAGUGACCCCCAAGCCCCCCAAACAUUACUUAAUAAUUUCUACUAGUUGAUACUUUUUUCCACUAAAUAAUGUUGAUUCUUGGGUCCUUUGCUUAAUGCAGGAAAAUCUAGGUCCUUAAAUGUGAGAAUUGACACACACACACACACACACACACACACACACACACACAAAUUAGGACCUGGCUGUUGACAGUCAAAAAGAAAAAUGAAGCCUCUCUAGAACUAAAAUGCAAAUAGACUGGAGAGCUGAACUUGGGGAUGAAAGAGAGGGGAGGCUAUACCCUAAGGCUAAAGAGUCAUUUGUGAUAUGAUUAAGAUCUCUGAUUGCGGAUGGGCGUUGGCUGGUGGAUGGGCAGUGGCUUGCGCCUAUAAUCCCAGCACUUUGGGAGGCCGAGGCAUGUGGAUCACUUGAAGUCAGGAGUUUUAAGACCAGCCUGGGCAACGUGGCGAAAUCCUGUCUACUAAAAAUACAAAAAUUAGCCAGGUAUGGUGGCGUACGCUUGUAAUCCCAGCUACUCAGGAGGCUGAGGCAGGAGAAUCACUUGAGACCCAGAGGCAGAGGUUGCAGUGAGCCGAGAUUGCGCCACUGCACUCCAGCCUGGCGACAGAGGAAGACUGUCAAAAAAAAGCCAGGCAUUGUGGCUCACACCUGUAAUCCCAGCACUUUGGGAGGCCUAGGCAGGUGAAUCACAAGGUCAGGAGAUCGAGACCAUCCUGGCUAACAGUGAAACCCUGUCUCUACUAAAAAAUACAAAAAAUUAGCCAAGUGUGGUGGUGGGCCUGUAGUCUAAGCUACUUGGGAGGUGGAGGUUGCAGUGAGCUGAGAUCGCGCCACUGCACUCCAGCCUGGGCAGUAGAGUGGGACUCCGUCUAAAAAAAAACAAAAAAAAACAAAAAAGAUCUCUGAUUGCCAUGUGGCAACAAUGCAAAGAAUAGUGGCACUCACAAAAUCUCUGUACAGCGGGAAGGGCCAGUGUGGAUUUCACAGGCCACAGUUUUGAUGGUUUUGAAUAAAAACCUAGGGUAACUGGUAACUAGUUGUGAAGAUAGAGGCUGUGAAGAAAAACACAGCAGGGAGAGGAAUGGGGUGAGGGUGGUUUGCUGCAUCAGAACCAUACAAGGAUUAGUGGAGGGGAUGGGGGUUGAAGGAUGGCCUGGGAGUUCUGGAUUUUCAUGUAUUGACAGCAAUGAUUAGCUGUGUUCUGUAUAAAUGACAGAGCAGCCAAACAGACAAAAGUGAACCUGUUAAUUGCACAAUUUUUUUUUCUUUUUUCUGAGACAGGGUUUCGCUCUUGUUGCCCAGGCUGGAGUGUGCAAUGGCGCGAUCUUGGCUCACCACAACCUCCGCCUCCCAGGUUCAAGAGAUUCUCCUGCCUCAGCCUCCCGAGUAGCUGGGAUUACAGGCGUGCGCCACCAUGCCUGGCUAAUUUUGUAUUUUUAGUAGAGAUGGGGUUUCUCCACGUUGGUCAGGCUGGUCUUGAACUCCCGACCUCAGGUGAUCCUCCUGCCUCCGCCUCCCCAAGUGCUGGGAUUACAGGCAUGAGCCACUGCACCCAGCCCAAAAAAUUUUUUAAAUAGGCUGGGCGCGGUGGCUCACGCCUGUAAUCCCAGUACUUGGGGAGGCCGAGGCAGGUGGAUCACAAGGUCAGGAGAUCGAGACCAUCCUGGCUAACAUGGUGAUACCCCGUCUACUAAAAAUACAAAAAAUUAGCCGGGCGUGGUGGCGGGCGCCUGUAGUCCCAGCUACUCGGGAGGGUGAGGCAGGAGAAUGGCGUGAACCUGGGAGGCAGAGCUUGCAGUGAGCCGAGAUUGCACUGCACUCUAGCCUGGGCGACAGAGUGAGACUCUGUCUCAAAAAAAAAAAAAAAUUUUUUUUAAUAGUUAAAUCUCAUUGUCUUCUCAUAAGAGUGGUGGUUUCUUAAAUACAUGCAUUAAAGUUCAUUUGUCGCUAGACAAAGCCCAUUUUUGUCAUUAAAUCCCUAGAUUUAGGAAGAAGGUGCUUUUUACAAAAUAAGAAAAGGAAUCCUGGAAAGGCUACAGUCAAUAUAAAGCCAUUUAAUAGCAUAGACCACCUGGAUCCUAAUCGCAUUUAUGGGAUUAUAUGGCUUCAUGUAACAUUUUAUUUUACUAGCCACAGUGUUAAAGUUACCAUGUGGAUGGGGAGGAAGGAGGUGGCAGUGAAAAGAAAUAUCUUAGAAAAUGAUUCUUAAGGGGAAUAAAGCAACUCUUAAAGAGAGGAAAUAUUUCAUAGCCUAAUCCCAAUUUUAAAGGUAAUGCUGGCUGGAUGUGGUGGCUCACACCUAUAAUCCCAGCACUUUUGGGAGGCCAGUGAUGGAGGAUAUCUUGAGCCCAGGAGUUUAAGACCCCAGCUCUGGCAACAUAGUGAGUCUCCGUCUCUACAAAAACUAAAAAAAUAAAAAUAAUAAUAAUAAUAAUAACUUUAAAAGUUAUUCUAAGUUAUUUAGCAAUUAUUUAAUGGCCUUUCUUGCUUAGCCUGGCAUGGUGGCACAUGCCUGUAGUCUCAGCUACUUGGGAGGCUAAGGUAGGAGGAUCUUUUGAGCCUGGAAAGUUGAGACUGCAGUGAGCCAUGGUUGUGCCACUGUACUCUGGGCAACAGAGUGAGACCUUGUCUCCAAAAAUACAAAUAUAUAAAUAAAGGUAAUGUGGAAACAUAGUCCCAUCAGUAUCAUAGUUCUUCCCACCCCACAAUCCCAGUGCUCCCUCCCCUAACAGCAUCUGACAUAUUAUAUAUCUUCAUUGAGUUUUUAAGUUCACUUCUUAACCCCAAAACAUAAAAAAAAAACCUGAAACCCAGUACAUUGGUCAAUAAAUAUUUAUUAUUGAAUAAAUAUUGCUACCAUCAGAUUCUCCUCUCUCCAUAUUUAUUCCAAAUUGAUUCCUUUGAAUCCUUAAGGAAACUAUGUGGAUAAAGGAUUGCACACACUAAGCUGUCAGGUUUUUCUAAGGGCUGUGCUGUCCUAUACCCACUUCAUAGUCAAAAGAUAAGGUCGCCUUAGAAGUCUGAGGGAAAAAAAAUGUGGAUUCAGGGUGAAACCCUGAGGCACAGUAGGUCCAGAUGGCCUUAACUUUGAAGAGAACAAAGUUACACCAAACUGCCUCUUCUUGCUUUCUCCCCUCUCCCCACAAAAAAAGGUAGAAAUUGCUGCCUCCCUAUGAACUGAGACACUGAUCUUUAAAAAAAAAAAAAAAAAAGUGUGACUCUGAAAAUACGGAGCUCCCUGCUAUUUAGUUACUGAAGAAAGUGCUUGGGUCUACCCACUGGACUGCCCAACUCCGCUGUCUUUGUAAAUCUGGUGUUUGGCCUGCAGUCCAUCUAAAGUUAGGCUGCACAUUCACCCACUGUUAAGUGUCUAACUGUGACCUCAACUGGUGAUAGGUGAAUCCCACCAGGAUUGUUUCUAUCCUGUGAUGCCUCGUUCCUGUUUUAACCUAGCUUCCCAAGCUCAUCCUAGAGCAACUUAGUUUAUCCUGGGGAAUUUAUAAAGGAAAUCAUGAGAAAUCAAAACUCAUCAUAAACAUUUAUUGGAAAAUGACUGUGAAUUAUGAGGUUCUUUCUUGUCAUCUAACAUAUAUAGUUGCUUCAUGAUCAUCUGUCCACCCUGUUGUUCAAUAUUUGGAACAGUUUCUUUCAACUUUAAAUUUUAGGGAAAUCUUAAAUAAUGGAUGGUUCUGCAUCAAAUGAUUCAUUUUACCGUAUUUCACUAAUUUCUGAUAGUAUGGUGGGAAAAUAAUUCUAUAAAAAGAUAACUGAGAAUUCAUUUUCACAAUUAUUCUAAGUUAUUUAGCAAAUAUUUAAUGGCCUUUCUUGCUUAGGACAAAUGUAUCAUAAUCAUCAAGUGUGCGAGCUUUUCUGUUUACCAAUGGCCAGUGAAAGUUUUAGGCUUUAUACAUACCAGUGAACUCUUUGAAAGGUCAGGAUACAUAGGCAUGUGUAUUUAUCCAGAAGUUGAUAUAUAUUUUUAAUUUCUUACAGAUUAUACCGAAAAGAAGUUCUAGAGAAAUUAAUAGAAAAAUGUGUUUCUAAAGGCUACGUCUUCCAGAUGGAGAUGAUUGUUCGGGCAAGACAGUUGAAUUAUACUAUUGGCGAGGUAUGCAACUGAUGCUAAAUAGUGUGUCAUGUUCCUGGUAAAGGAGCAGUAAGGUUUAGAAUUUUUAUAAUAAAAAGUUUAACUUUCAUAACUGCUAAAUUGUGGAGGUCUUCUAGUUGUUUAGAAUAUUCAUGCACAAAGGGUAAAAAUUCAUAUUAGUACAUUUGAACAGUAAGAUUUAAAACAUUAACAGUCAGCAUUCUCUUUUAAAUAAUUAAAAGUUCCUGGUACUUUCUCAAUCCUAGCCCUUUCUUCUAACUAAUCAGCAUUAUGGACUGAGUCUCUUUGCUUCUUUUCCUUUUGUCACCGCCAAUGGCCACCAUACUUUAAAAUGAAUGAUGAGUUCCAUAUGUCCAUUUCCUGUUAGUAAGAGAAGACCAGGAAUUACAGAGCAAGGAGGUGGUGAUCUGUAAUAUUUAGGGCUCGUUAGUGAGCUCUUAGGGUAGGGAAGACUCUCCUCAUUUAAUAGUAAAACUCUUAUUCAGAGCAAGAAAAUAGCUAUGGAAUGUCACUUCUCUUGUGGAAGUUACAAGCUAUUUUACUUAAUGCUAAACCAUUGUAGCUAAAUUUGACAAGUGAAAAAUCUACGCACAAGGCCAUUUUACUUUUGGAGUAUAAUUUUUCCUUGAAAUGCAAACUGAAACUUGAGUAAACCAAGGUAAUACCUAGAAUCAGUGCUUUUUAAACAGUUGCAGAUUUGUUUCAUGUGACCUAUCUUUAGAUAAUGCAUGUUUAAUUUUAAAGACUUGGAGAUACACACAGUUGCUUUCAUAAUCCCCUAAUUUUAUACUUACUUUAAGGACCUCUGUUGUAGGACUAAUCCUAUUUCUGUUGUGUUGGUAAUGUGGUAUACCGGCUAAGCUGCCUAAUUGUUUUUAAAGACUAACGUUACUUUUUUUUUUUUAAACUAGGUUCCAAUAUCAUUUGUGGAUCGUGUUUAUGGUGAAUCCAAGUUGGGAGGAAAUGAAAUAGUAUCUUUCUUGAAAGGAUUAUUGACUCUUUUUGCUACUACAUAAAAGAAAGAUACUCAUUUAUAGUUACGUUCAUUUCAGGUUAAACAUGAAAGAAGCCUGGUUACUGAUUUGUAUAAAAUGUACUCUUAAAGUAUAAAAUAUAAGGUAAGGUAAAUUUCAUGCAUCUUUUUAUGAAGACCACCUAUUUUAUAUUUCAAAUUAAAUAAUUUUAAAGUUGCUGGCCUAAUGAGCAAUGUUCUCAAUUUUCGUUUUCAUUUUGCUGUAUUGAGACCUAUAAAUAAAUGUAUAUUUUUUUUUGCAUAAAGUA\n",
    "# Write the example FASTA to a file ### REQUIRED\n",
    "fasta_path = Path(\"example.fasta\")\n",
    "fasta_path.write_text(example_fasta)\n",
    "\n",
    "\n",
    "output_dir = Path(\"outputs\")\n",
    "output_cif_paths = run_inference(\n",
    "    fasta_file=fasta_path,\n",
    "    output_dir=output_dir,\n",
    "    num_trunk_recycles=3,\n",
    "    num_diffn_timesteps=200,\n",
    "    seed=42,\n",
    "    device=torch.device(\"cuda:0\"),  # Use \"cpu\" if no GPU is available\n",
    "    use_esm_embeddings=True,\n",
    ")\n",
    "\n",
    "\n",
    "pdb_files = list(output_dir.glob(\"*.pdb\"))\n",
    "print(\"Generated PDB files:\")\n",
    "for pdb_file in pdb_files:\n",
    "    print(pdb_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc201fb3-385a-4bdd-8c97-ba810abeb825",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 11254\n"
     ]
    }
   ],
   "source": [
    "### COLLECTING MATCHED SEQUENCES\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Load the data\n",
    "file_path = '6048D_rawCounts.txt'\n",
    "df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "# Columns of interest\n",
    "unmod_cols = ['MR10_unmod_1', 'MR11_unmod_2', 'MR12_unmod_3']\n",
    "nt_cols = ['MR1_NT_1', 'MR2_NT_2', 'MR3_NT_3']\n",
    "amide_cols = ['MR4_Amide3_1', 'MR5_Amide3_2', 'MR6_Amide3_3']\n",
    "gna_cols = ['MR7_GNA7_1', 'MR8_GNA7_2', 'MR9_GNA7_3']\n",
    "\n",
    "# Function to fetch sequences from Ensembl\n",
    "def fetch_sequences_batch(ensembl_ids):\n",
    "    url = \"https://rest.ensembl.org/sequence/id\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"ids\": ensembl_ids}\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Prepare to search for sequences with \"AATCCTAT\"\n",
    "batch_size = 50\n",
    "ensembl_ids = list(df.index)\n",
    "matches = []\n",
    "\n",
    "# Iterate through the Ensembl IDs in batches\n",
    "for i in range(0, len(ensembl_ids), batch_size):\n",
    "    batch_ids = ensembl_ids[i:i + batch_size]\n",
    "    sequences = fetch_sequences_batch(batch_ids)\n",
    "    \n",
    "    if sequences:\n",
    "        for seq_info in sequences:\n",
    "            sequence = seq_info['seq']\n",
    "            ensembl_id = seq_info['id']\n",
    "            if 'AATCCTAT' in sequence:\n",
    "                matches.append(ensembl_id)\n",
    "\n",
    "# Output matched Ensembl IDs to file\n",
    "with open(\"matched_sequences_AATCCTAT.txt\", \"w\") as file:\n",
    "    for match in matches:\n",
    "        file.write(f\"{match}\\n\")\n",
    "\n",
    "# Print the number of matches\n",
    "print(f\"Total matches found: {len(matches)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cad792cd-03c2-4220-ac56-23333159984d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of entries: 58884\n",
      "Number of entries after removal of matched ENS IDs: 47630\n",
      "\n",
      "Amide vs NT (before mask):\n",
      "Number of data points with log2FC > 0.25: 13261\n",
      "Number of data points with log2FC < -0.25: 15170\n",
      "Total number of data points with |log2FC| > 0.25: 28431\n",
      "\n",
      "Amide vs NT (after mask):\n",
      "Number of data points with log2FC > 0.25: 877\n",
      "Number of data points with log2FC < -0.25: 722\n",
      "Total number of data points with |log2FC| > 0.25: 1599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/mrichte3/miniconda3/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Read ENS IDs to exclude from the matched_sequences_AATCCTAT.txt file\n",
    "excluded_ens_ids = []\n",
    "with open('matched_sequences_AATCCTAT.txt', 'r') as f:\n",
    "    excluded_ens_ids = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Step 2: Read the raw counts data from 6048D_rawCounts.txt\n",
    "df = pd.read_csv('6048D_rawCounts.txt', sep='\\t', index_col=0)\n",
    "\n",
    "# Step 3: Filter out ENS IDs from matched_sequences_AATCCTAT.txt\n",
    "initial_count = df.shape[0]\n",
    "df_filtered = df[~df.index.isin(excluded_ens_ids)]\n",
    "final_count = df_filtered.shape[0]\n",
    "\n",
    "# Print number of entries before and after removal\n",
    "print(f\"Initial number of entries: {initial_count}\")\n",
    "print(f\"Number of entries after removal of matched ENS IDs: {final_count}\")\n",
    "\n",
    "# Step 4: Select columns of interest (NT and Amide columns only)\n",
    "columns_of_interest = [\n",
    "    'MR1_NT_1', 'MR2_NT_2', 'MR3_NT_3',\n",
    "    'MR4_Amide3_1', 'MR5_Amide3_2', 'MR6_Amide3_3'\n",
    "]\n",
    "df_counts = df_filtered[columns_of_interest]\n",
    "\n",
    "# Step 5: Normalize the counts\n",
    "total_counts = df_counts.sum(axis=0)\n",
    "scaling_factors = total_counts / total_counts.mean()\n",
    "df_normalized = df_counts.div(scaling_factors, axis=1)\n",
    "\n",
    "# Step 6: Calculate mean counts for each group\n",
    "nt_cols = ['MR1_NT_1', 'MR2_NT_2', 'MR3_NT_3']\n",
    "amide_cols = ['MR4_Amide3_1', 'MR5_Amide3_2', 'MR6_Amide3_3']\n",
    "\n",
    "df_normalized['mean_nt'] = df_normalized[nt_cols].mean(axis=1)\n",
    "df_normalized['mean_amide'] = df_normalized[amide_cols].mean(axis=1)\n",
    "\n",
    "# Step 7: Calculate Log2 Fold Changes (Amide vs NT)\n",
    "df_normalized['log2FC_amide_vs_nt'] = np.log2(df_normalized['mean_amide'] / df_normalized['mean_nt'])\n",
    "\n",
    "# Step 8: Calculate counts where log2FC > 0.25 or log2FC < -0.25 for Amide vs NT\n",
    "amide_log2fc = df_normalized['log2FC_amide_vs_nt']\n",
    "amide_positive = (amide_log2fc > 0.25).sum()\n",
    "amide_negative = (amide_log2fc < -0.25).sum()\n",
    "amide_total = amide_positive + amide_negative\n",
    "\n",
    "# Step 9: Print the results for Amide vs NT before the mask\n",
    "print(\"\\nAmide vs NT (before mask):\")\n",
    "print(f\"Number of data points with log2FC > 0.25: {amide_positive}\")\n",
    "print(f\"Number of data points with log2FC < -0.25: {amide_negative}\")\n",
    "print(f\"Total number of data points with |log2FC| > 0.25: {amide_total}\")\n",
    "\n",
    "# Step 10: Apply the mask to filter data where mean NT counts are greater than 10^1.5\n",
    "mask = df_normalized['mean_nt'] > 10**1.5\n",
    "df_masked = df_normalized[mask]\n",
    "\n",
    "# Step 11: Recalculate counts where log2FC > 0.25 or log2FC < -0.25 for Amide vs NT after the mask\n",
    "amide_log2fc_masked = df_masked['log2FC_amide_vs_nt']\n",
    "amide_positive_masked = (amide_log2fc_masked > 0.25).sum()\n",
    "amide_negative_masked = (amide_log2fc_masked < -0.25).sum()\n",
    "amide_total_masked = amide_positive_masked + amide_negative_masked\n",
    "\n",
    "# Step 12: Print the results for Amide vs NT after applying the mask\n",
    "print(\"\\nAmide vs NT (after mask):\")\n",
    "print(f\"Number of data points with log2FC > 0.25: {amide_positive_masked}\")\n",
    "print(f\"Number of data points with log2FC < -0.25: {amide_negative_masked}\")\n",
    "print(f\"Total number of data points with |log2FC| > 0.25: {amide_total_masked}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb1c681-c116-4d98-b356-d120f3284add",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### DECENT ALIGNMENT, BUT HAS THESE SHORT SEQUENCES. CANNOT FIGURE OUT THE ISSUE\n",
    "import pandas as pd\n",
    "import requests\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "\n",
    "def fetch_sequences_batch(ensembl_ids):\n",
    "    url = \"https://rest.ensembl.org/sequence/id\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"ids\": ensembl_ids}\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def scan_for_high_similarity(seq_info):\n",
    "    sequence = seq_info['seq']\n",
    "    ensembl_id = seq_info['id']\n",
    "    seed_sequence = \"AATCCTAT\"\n",
    "    \n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Check if seed sequence is present (side check)\n",
    "    contains_seed = seed_sequence in sequence\n",
    "    \n",
    "    # Perform alignment\n",
    "    alignments = pairwise2.align.localms(sequence, target_sequence, 2, -1, -5, -2)\n",
    "    best_alignment = alignments[0] if alignments else None\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    if best_alignment:\n",
    "        score = best_alignment[2]\n",
    "        start = best_alignment[3]\n",
    "        end = best_alignment[4]\n",
    "        alignment_str = format_alignment(*best_alignment)\n",
    "        return f\"{ensembl_id}: Sequence length={len(sequence)}, Contains seed={contains_seed}, Alignment score={score:.2f}, Alignment range=({start}, {end}), Time elapsed={elapsed_time:.2f}s\\n{alignment_str}\"\n",
    "    else:\n",
    "        return f\"{ensembl_id}: Sequence length={len(sequence)}, Contains seed={contains_seed}, No significant alignment found, Time elapsed={elapsed_time:.2f}s\"\n",
    "\n",
    "target_sequence = \"ATCTCCTAATATGAATCCTAT\"\n",
    "\n",
    "df = pd.read_csv('6048D_rawCounts.txt', sep='\\t', index_col=0)\n",
    "\n",
    "ensembl_ids = list(df.index)\n",
    "ensembl_ids = [\"ENSG00000100811\", \"ENSG00000100811\"]\n",
    "batch_size = 50\n",
    "batch_ids = ensembl_ids[:batch_size]\n",
    "\n",
    "sequences = fetch_sequences_batch(batch_ids)\n",
    "\n",
    "if sequences:\n",
    "    num_cores = cpu_count()\n",
    "    print(f\"Using {num_cores} CPU cores for parallel processing\")\n",
    "    with Pool(num_cores) as pool:\n",
    "        for result in pool.imap_unordered(scan_for_high_similarity, sequences):\n",
    "            print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30b29c1-5d7d-47c4-9c03-58aef9291120",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data rcvd\n",
      "started alignment\n",
      "ended alignment\n",
      "Alignment details:\n",
      "\n",
      "TCTCCTAATA TCTCCTAATA\n",
      "ENSG00000044459: Alignment score=23.00, Time elapsed=0.28s\n"
     ]
    }
   ],
   "source": [
    "## GOOD SETTINGS FOR NCBI BLAST-LIKE ALIGNMENT\n",
    "import pandas as pd\n",
    "import requests\n",
    "from Bio import Align\n",
    "import time\n",
    "\n",
    "def fetch_single_sequence(ensembl_id):\n",
    "    url = \"https://rest.ensembl.org/sequence/id\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"ids\": [ensembl_id]}  # Requesting only the single sequence\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[0]  # Return the single sequence from response\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def scan_for_high_similarity(seq_info):\n",
    "    sequence = seq_info['seq']\n",
    "    ensembl_id = seq_info['id']\n",
    "    seed_sequence = \"AATCCTAT\"\n",
    "    \n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Check if seed sequence is present (side check)\n",
    "    contains_seed = seed_sequence in sequence\n",
    "    \n",
    "    # Perform alignment using Bio.Align.PairwiseAligner\n",
    "    aligner = Align.PairwiseAligner()\n",
    "    aligner.mode = 'local'  # Local alignment like BLAST\n",
    "    aligner.match_score = 2  # Match score of +2\n",
    "    aligner.mismatch_score = -3  # Mismatch score of -3 (BLAST-like)\n",
    "    aligner.open_gap_score = -5  # Gap opening penalty like BLAST\n",
    "    aligner.extend_gap_score = -2  # Gap extension penalty like BLAST\n",
    "\n",
    "    print(\"started alignment\")\n",
    "    alignments = aligner.align(sequence, target_sequence)\n",
    "    print(\"ended alignment\")\n",
    "    \n",
    "    best_alignment = alignments[0] if alignments else None\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    if best_alignment:\n",
    "        aligned_seq = best_alignment.target  # The aligned sequence from the gene\n",
    "        aligned_target = best_alignment.query  # The aligned sequence from the target\n",
    "        score = best_alignment.score\n",
    "        aligned_positions = best_alignment.aligned\n",
    "\n",
    "        print(f\"Alignment details:\\n\")\n",
    "        display_alignment(sequence, target_sequence, aligned_positions)\n",
    "        return f\"{ensembl_id}: Alignment score={score:.2f}, Time elapsed={elapsed_time:.2f}s\"\n",
    "    else:\n",
    "        return f\"{ensembl_id}: Sequence length={len(sequence)}, Contains seed={contains_seed}, No significant alignment found, Time elapsed={elapsed_time:.2f}s\"\n",
    "\n",
    "def display_alignment(sequence, target_sequence, alignment_positions):\n",
    "    target_alignments = alignment_positions[1]  # Target sequence positions\n",
    "    gene_alignments = alignment_positions[0]  # Gene sequence positions\n",
    "\n",
    "    for i, (target_range, gene_range) in enumerate(zip(target_alignments, gene_alignments)):\n",
    "        target_aligned = target_sequence[target_range[0]:target_range[1]]\n",
    "        gene_aligned = sequence[gene_range[0]:gene_range[1]]\n",
    "        print(f\"{target_aligned} {gene_aligned}\")\n",
    "        break\n",
    "\n",
    "target_sequence = \"ATCTCCTAATATGAATCCTAT\"\n",
    "\n",
    "# Fetch a single sequence\n",
    "ensembl_id = \"ENSG00000044459\"\n",
    "\n",
    "sequence_data = fetch_single_sequence(ensembl_id)\n",
    "print(\"data rcvd\")\n",
    "\n",
    "if sequence_data:\n",
    "    # Process the single sequence\n",
    "    result = scan_for_high_similarity(sequence_data)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b8498-fc70-41f6-8989-13b89e4696b4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## WILL PRINT THE FIRST ALIGNMENT ENTRY, NO TRIMMING\n",
    "import pandas as pd\n",
    "import requests\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "import time\n",
    "\n",
    "def fetch_single_sequence(ensembl_id):\n",
    "    url = \"https://rest.ensembl.org/sequence/id\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"ids\": [ensembl_id]}\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def scan_for_high_similarity(seq_info):\n",
    "    sequence = seq_info['seq']\n",
    "    ensembl_id = seq_info['id']\n",
    "    seed_sequence = \"AATCCTAT\"\n",
    "    start_time = time.time()\n",
    "    contains_seed = seed_sequence in sequence\n",
    "    alignments = pairwise2.align.globalmx(sequence, target_sequence, 2, -1)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    if alignments:\n",
    "        best_alignment = alignments[0]\n",
    "        aligned_seq, aligned_target, score, begin, end = best_alignment\n",
    "        alignment_str = format_alignment(aligned_seq, aligned_target, score, begin, end, full_sequences=False)\n",
    "\n",
    "        # Trim each line to a maximum of 50 characters\n",
    "        trimmed_alignment = \"\\n\".join([line[:50] for line in alignment_str.splitlines()])\n",
    "\n",
    "        # Print all available data\n",
    "        print(f\"Alignment Data for {ensembl_id}:\")\n",
    "        print(f\"Alignment Start: {begin}\")\n",
    "        print(f\"Alignment End: {end}\")\n",
    "        print(f\"Alignment Score: {score}\")\n",
    "        print(f\"Trimmed Alignment:\\n{trimmed_alignment}\")\n",
    "\n",
    "        # Now iterate over all alignments and print them in trimmed form\n",
    "        print(\"\\nAll Alignments (trimmed to 50 characters per line):\")\n",
    "        for a in alignments:\n",
    "            alignment_str = format_alignment(*a)\n",
    "            trimmed_a = \"\\n\".join([line for line in alignment_str.splitlines()])\n",
    "            print(trimmed_a)\n",
    "            break\n",
    "        \n",
    "        return f\"{ensembl_id}: Sequence length={len(sequence)}, Contains seed={contains_seed}, Alignment score={score:.2f}, Alignment range=({begin}, {end}), Time elapsed={elapsed_time:.2f}s\"\n",
    "    else:\n",
    "        return f\"{ensembl_id}: Sequence length={len(sequence)}, Contains seed={contains_seed}, No significant alignment found, Time elapsed={elapsed_time:.2f}s\"\n",
    "\n",
    "target_sequence = \"ATCTCCTAATATGAATCCTAT\"\n",
    "ensembl_id = \"ENSG00000051382\"\n",
    "sequence_data = fetch_single_sequence(ensembl_id)\n",
    "print(\"Data received\")\n",
    "\n",
    "if sequence_data:\n",
    "    result = scan_for_high_similarity(sequence_data)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd654bc-d216-4bce-a444-5f7ae8465434",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## WILL PRINT ALL THE RESULTS, BUT TRIMS EACH ONE\n",
    "import pandas as pd\n",
    "import requests\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "import time\n",
    "\n",
    "def fetch_single_sequence(ensembl_id):\n",
    "    url = \"https://rest.ensembl.org/sequence/id\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"ids\": [ensembl_id]}\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def scan_for_high_similarity(seq_info):\n",
    "    sequence = seq_info['seq']\n",
    "    ensembl_id = seq_info['id']\n",
    "    seed_sequence = \"AATCCTAT\"\n",
    "    start_time = time.time()\n",
    "    contains_seed = seed_sequence in sequence\n",
    "    alignments = pairwise2.align.globalmx(sequence, target_sequence, 2, -1)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    if alignments:\n",
    "        best_alignment = alignments[0]\n",
    "        aligned_seq, aligned_target, score, begin, end = best_alignment\n",
    "        alignment_str = format_alignment(aligned_seq, aligned_target, score, begin, end, full_sequences=False)\n",
    "\n",
    "        # Trim each line to a maximum of 50 characters\n",
    "        trimmed_alignment = \"\\n\".join([line[:50] for line in alignment_str.splitlines()])\n",
    "\n",
    "        # Print all available data\n",
    "        print(f\"Alignment Data for {ensembl_id}:\")\n",
    "        print(f\"Alignment Start: {begin}\")\n",
    "        print(f\"Alignment End: {end}\")\n",
    "        print(f\"Alignment Score: {score}\")\n",
    "        print(f\"Trimmed Alignment:\\n{trimmed_alignment}\")\n",
    "\n",
    "        # Now iterate over all alignments and print them in trimmed form\n",
    "        print(\"\\nAll Alignments (trimmed to 50 characters per line):\")\n",
    "        for a in alignments:\n",
    "            alignment_str = format_alignment(*a)\n",
    "            trimmed_a = \"\\n\".join([line[:50] for line in alignment_str.splitlines()])\n",
    "            print(trimmed_a)\n",
    "        \n",
    "        return f\"{ensembl_id}: Sequence length={len(sequence)}, Contains seed={contains_seed}, Alignment score={score:.2f}, Alignment range=({begin}, {end}), Time elapsed={elapsed_time:.2f}s\"\n",
    "    else:\n",
    "        return f\"{ensembl_id}: Sequence length={len(sequence)}, Contains seed={contains_seed}, No significant alignment found, Time elapsed={elapsed_time:.2f}s\"\n",
    "\n",
    "target_sequence = \"ATCTCCTAATATGAATCCTAT\"\n",
    "ensembl_id = \"ENSG00000051382\"\n",
    "sequence_data = fetch_single_sequence(ensembl_id)\n",
    "print(\"Data received\")\n",
    "\n",
    "if sequence_data:\n",
    "    result = scan_for_high_similarity(sequence_data)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae468aa-5078-4767-8df4-acae4d5466da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "\n",
    "def get_entrez_id_from_ensembl(ensembl_id):\n",
    "    url = f\"https://rest.ensembl.org/xrefs/id/{ensembl_id}?external_db=EntrezGene\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            return data[0][\"primary_id\"]  # Return the Entrez Gene ID\n",
    "    return None\n",
    "\n",
    "ensembl_id = \"ENSG00000100811\" ###   \"ENSG00000051382\" ###  \n",
    "entrez_id = get_entrez_id_from_ensembl(ensembl_id)\n",
    "\n",
    "if entrez_id:\n",
    "    print(f\"Fetched Entrez ID for {ensembl_id}: {entrez_id}\")\n",
    "    target_sequence = \"ATCTCCTAATATGAATCCTAT\"\n",
    "\n",
    "    print(f\"Running BLAST using Entrez ID {entrez_id} as the subject...\")\n",
    "\n",
    "    # Run BLAST using the Entrez ID\n",
    "    result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", target_sequence, entrez_query=f\"{entrez_id} AND txid9606[ORGN]\", expect=10, short_query=True)\n",
    "\n",
    "    with open(\"blast_result.xml\", \"w\") as out_handle:\n",
    "        out_handle.write(result_handle.read())\n",
    "\n",
    "    with open(\"blast_result.xml\") as result_handle:\n",
    "        blast_record = NCBIXML.read(result_handle)\n",
    "\n",
    "    # Only get the first alignment and its score\n",
    "    if blast_record.alignments:\n",
    "        alignment = blast_record.alignments[0]\n",
    "        print(f\"Alignment: {alignment.title}\")\n",
    "        hsp = alignment.hsps[0]  # First HSP (High Scoring Pair)\n",
    "        print(f\"Score: {hsp.score}\")\n",
    "        print(f\"Query/Match/Subject:\\n{hsp.query}\\n{hsp.match}\\n{hsp.sbjct}\")\n",
    "        # print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "else:\n",
    "    print(f\"Could not fetch the Entrez ID for Ensembl ID {ensembl_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c6aa9c8-50f6-48a5-8d61-d01ea2ab6d6d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched Entrez ID for ENSG00000100811: 7528\n",
      "Running BLAST using Entrez ID 7528 as the subject...\n",
      "result rcvd from blast\n",
      "Alignment: gi|1653960621|ref|NM_003403.5| Homo sapiens YY1 transcription factor (YY1), mRNA\n",
      "Score: 10.0\n",
      "Query/Match/Subject:\n",
      "ATGAATCCTA\n",
      "||||||||||\n",
      "ATGAATCCTA\n",
      "Unmatched Gene Sequence Before Alignment: ATGAATCCTA\n",
      "Unmatched Gene Sequence After Alignment: \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "\n",
    "def get_entrez_id_from_ensembl(ensembl_id):\n",
    "    url = f\"https://rest.ensembl.org/xrefs/id/{ensembl_id}?external_db=EntrezGene\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            return data[0][\"primary_id\"]\n",
    "    return None\n",
    "\n",
    "ensembl_id = \"ENSG00000100811\"\n",
    "entrez_id = get_entrez_id_from_ensembl(ensembl_id)\n",
    "\n",
    "if entrez_id:\n",
    "    print(f\"Fetched Entrez ID for {ensembl_id}: {entrez_id}\")\n",
    "    target_sequence = \"ATCTCCTAATATGAATCCTAT\"\n",
    "\n",
    "    print(f\"Running BLAST using Entrez ID {entrez_id} as the subject...\")\n",
    "\n",
    "    result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", target_sequence, entrez_query=f\"{entrez_id} AND txid9606[ORGN]\", expect=10, short_query=True)\n",
    "    print(\"result rcvd from blast\")\n",
    "\n",
    "    with open(\"blast_result.xml\", \"w\") as out_handle:\n",
    "        out_handle.write(result_handle.read())\n",
    "\n",
    "    with open(\"blast_result.xml\") as result_handle:\n",
    "        blast_record = NCBIXML.read(result_handle)\n",
    "\n",
    "    if blast_record.alignments:\n",
    "        alignment = blast_record.alignments[0]\n",
    "        print(f\"Alignment: {alignment.title}\")\n",
    "        hsp = alignment.hsps[0]\n",
    "        print(f\"Score: {hsp.score}\")\n",
    "\n",
    "        aligned_query = hsp.query\n",
    "        aligned_gene = hsp.sbjct\n",
    "        match_positions = hsp.match\n",
    "        start = hsp.sbjct_start\n",
    "        end = hsp.sbjct_end\n",
    "\n",
    "        gene_sequence = alignment.hsps[0].sbjct\n",
    "        target_len = len(target_sequence)\n",
    "        aligned_len = len(aligned_query)\n",
    "\n",
    "        before_len = start - 1\n",
    "        after_len = target_len - aligned_len - before_len\n",
    "\n",
    "        unmatched_before = gene_sequence[:before_len] if before_len > 0 else \"\"\n",
    "        unmatched_after = gene_sequence[end:end + after_len] if after_len > 0 else \"\"\n",
    "\n",
    "        print(f\"Query/Match/Subject:\\n{aligned_query}\\n{match_positions}\\n{aligned_gene}\")\n",
    "        print(f\"Unmatched Gene Sequence Before Alignment: {unmatched_before}\")\n",
    "        print(f\"Unmatched Gene Sequence After Alignment: {unmatched_after}\")\n",
    "else:\n",
    "    print(f\"Could not fetch the Entrez ID for Ensembl ID {ensembl_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d58c9519-6f81-4706-bfc7-f7a433e51378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accession number: NM_003403\n",
      "Full gene sequence length: 6534\n",
      "Aligned region: ATGAATCCTA\n",
      "Aligned region found at position: 1454\n",
      "Aligned region ends at position: 1463\n",
      "Complete region of gene corresponding to target sequence: AATTTTAAAAATGAATCCTAC\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "target_sequence = \"ATCTCCTAATATGAATCCTAT\"\n",
    "Entrez.email = \"1800420@gmail.com\"\n",
    "ensembl_id = \"ENSG00000100811\"\n",
    "\n",
    "if blast_record.alignments:\n",
    "    alignment = blast_record.alignments[0]\n",
    "    \n",
    "    accession = alignment.accession\n",
    "    print(f\"Accession number: {accession}\")\n",
    "    \n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"fasta\", retmode=\"text\")\n",
    "    full_gene_sequence = handle.read().split(\"\\n\", 1)[1].replace(\"\\n\", \"\")\n",
    "    \n",
    "    gene_length = len(full_gene_sequence)\n",
    "    print(f\"Full gene sequence length: {gene_length}\")\n",
    "    \n",
    "    aligned_region = alignment.hsps[0].sbjct\n",
    "    print(f\"Aligned region: {aligned_region}\")\n",
    "    \n",
    "    match_position = full_gene_sequence.find(aligned_region)\n",
    "    \n",
    "    if match_position != -1:\n",
    "        print(f\"Aligned region found at position: {match_position + 1}\")\n",
    "        print(f\"Aligned region ends at position: {match_position + len(aligned_region)}\")\n",
    "        \n",
    "        target_length = len(target_sequence)\n",
    "        aligned_length = len(aligned_region)\n",
    "\n",
    "        bases_needed_before = target_length - aligned_length - 1  # 10 before\n",
    "        bases_needed_after = 1  # 1 after\n",
    "        \n",
    "        start_position = max(0, match_position - bases_needed_before)\n",
    "        end_position = min(gene_length, match_position + aligned_length + bases_needed_after)\n",
    "\n",
    "        complete_region = full_gene_sequence[start_position:end_position]\n",
    "\n",
    "        print(f\"Complete region of gene corresponding to target sequence: {complete_region}\")\n",
    "    else:\n",
    "        print(\"Aligned region not found in the full gene sequence.\")\n",
    "else:\n",
    "    print(\"No alignment found in the BLAST result.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05494d2d-0171-4ef8-a96e-c220c23a4f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data rcvd\n",
      "started alignment\n",
      "ended alignment\n",
      "Alignment details:\n",
      "\n",
      "AATATGAATCCTA AAAATGAATCCTA\n",
      "ENSG00000100811: Alignment score=21.00, Time elapsed=0.02s\n"
     ]
    }
   ],
   "source": [
    "## GOOD SETTINGS FOR NCBI BLAST-LIKE ALIGNMENT\n",
    "import pandas as pd\n",
    "import requests\n",
    "from Bio import Align\n",
    "import time\n",
    "\n",
    "def fetch_single_sequence(ensembl_id):\n",
    "    url = \"https://rest.ensembl.org/sequence/id\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"ids\": [ensembl_id]}  # Requesting only the single sequence\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[0]  # Return the single sequence from response\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def scan_for_high_similarity(seq_info):\n",
    "    sequence = seq_info['seq']\n",
    "    ensembl_id = seq_info['id']\n",
    "    seed_sequence = \"AATCCTAT\"\n",
    "    \n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Check if seed sequence is present (side check)\n",
    "    contains_seed = seed_sequence in sequence\n",
    "    \n",
    "    # Perform alignment using Bio.Align.PairwiseAligner\n",
    "    aligner = Align.PairwiseAligner()\n",
    "    aligner.mode = 'local'  # Local alignment like BLAST\n",
    "    aligner.match_score = 2  # Match score of +2\n",
    "    aligner.mismatch_score = -3  # Mismatch score of -3 (BLAST-like)\n",
    "    aligner.open_gap_score = -5  # Gap opening penalty like BLAST\n",
    "    aligner.extend_gap_score = -2  # Gap extension penalty like BLAST\n",
    "\n",
    "    print(\"started alignment\")\n",
    "    alignments = aligner.align(sequence, target_sequence)\n",
    "    print(\"ended alignment\")\n",
    "    \n",
    "    best_alignment = alignments[0] if alignments else None\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    if best_alignment:\n",
    "        aligned_seq = best_alignment.target  # The aligned sequence from the gene\n",
    "        aligned_target = best_alignment.query  # The aligned sequence from the target\n",
    "        score = best_alignment.score\n",
    "        aligned_positions = best_alignment.aligned\n",
    "\n",
    "        print(f\"Alignment details:\\n\")\n",
    "        display_alignment(sequence, target_sequence, aligned_positions)\n",
    "        return f\"{ensembl_id}: Alignment score={score:.2f}, Time elapsed={elapsed_time:.2f}s\"\n",
    "    else:\n",
    "        return f\"{ensembl_id}: Sequence length={len(sequence)}, Contains seed={contains_seed}, No significant alignment found, Time elapsed={elapsed_time:.2f}s\"\n",
    "\n",
    "def display_alignment(sequence, target_sequence, alignment_positions):\n",
    "    target_alignments = alignment_positions[1]  # Target sequence positions\n",
    "    gene_alignments = alignment_positions[0]  # Gene sequence positions\n",
    "\n",
    "    for i, (target_range, gene_range) in enumerate(zip(target_alignments, gene_alignments)):\n",
    "        target_aligned = target_sequence[target_range[0]:target_range[1]]\n",
    "        gene_aligned = sequence[gene_range[0]:gene_range[1]]\n",
    "        print(f\"{target_aligned} {gene_aligned}\")\n",
    "\n",
    "target_sequence = \"ATCTCCTAATATGAATCCTAT\"\n",
    "\n",
    "# Fetch a single sequence\n",
    "ensembl_id = \"ENSG00000100811\"\n",
    "sequence_data = fetch_single_sequence(ensembl_id)\n",
    "print(\"data rcvd\")\n",
    "\n",
    "if sequence_data:\n",
    "    # Process the single sequence\n",
    "    result = scan_for_high_similarity(sequence_data)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2a8e6-9d06-4262-a292-1d4e20635670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALIGNS SEQUENCES OFFLINE, MAPS IDS BACK TO THE ORIGINAL. prints results first, then id\n",
    "import csv\n",
    "from Bio import Align\n",
    "import sys\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "# Load the mapping between original_id and updated_id\n",
    "def load_id_mapping(mapping_file):\n",
    "    id_map = {}\n",
    "    with open(mapping_file, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            id_map[row['updated_id']] = row['original_id']\n",
    "    return id_map\n",
    "\n",
    "def scan_for_high_similarity(ensembl_id, sequence):\n",
    "    seed_sequence = \"AATCCTAT\"\n",
    "    \n",
    "    aligner = Align.PairwiseAligner()\n",
    "    aligner.mode = 'local'\n",
    "    aligner.match_score = 2\n",
    "    aligner.mismatch_score = -3\n",
    "    aligner.open_gap_score = -5\n",
    "    aligner.extend_gap_score = -2\n",
    "\n",
    "    alignments = aligner.align(sequence, target_sequence)\n",
    "    \n",
    "    best_alignment = alignments[0] if alignments else None\n",
    "    \n",
    "    if best_alignment:\n",
    "        aligned_seq = best_alignment.target\n",
    "        aligned_target = best_alignment.query\n",
    "        score = best_alignment.score\n",
    "        aligned_positions = best_alignment.aligned\n",
    "\n",
    "        display_alignment(sequence, target_sequence, aligned_positions)\n",
    "        return f\"{ensembl_id}: Alignment score={score:.2f}\"\n",
    "    else:\n",
    "        return f\"{ensembl_id}: No significant alignment found\"\n",
    "\n",
    "def display_alignment(sequence, target_sequence, alignment_positions):\n",
    "    target_alignments = alignment_positions[1]  # Target sequence positions\n",
    "    gene_alignments = alignment_positions[0]  # Gene sequence positions\n",
    "\n",
    "    for i, (target_range, gene_range) in enumerate(zip(target_alignments, gene_alignments)):\n",
    "        target_aligned = target_sequence[target_range[0]:target_range[1]]\n",
    "        gene_aligned = sequence[gene_range[0]:gene_range[1]]\n",
    "        print(f\"{target_aligned} {gene_aligned}\")\n",
    "        # break\n",
    "######################code2\n",
    "    gene_aligned = \"\"\n",
    "    for gene_range in gene_alignments:\n",
    "        gene_aligned += sequence[gene_range[0]:gene_range[1]]\n",
    "    print(f\"{gene_aligned}\")\n",
    "\n",
    "# Load the original to updated ID map\n",
    "id_mapping = load_id_mapping('updated_ids.csv')\n",
    "\n",
    "input_files = ['sequences_from_updated.csv', 'sequences.csv']\n",
    "target_sequence = \"ATCTCCTAATATGAATCCTAT\" # 271\n",
    "                    \n",
    "             \n",
    "\n",
    "for input_file in input_files:\n",
    "    with open(input_file, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        \n",
    "        for row in reader:\n",
    "            ensembl_id = row['ensemble_id']\n",
    "            sequence = row['sequence']\n",
    "            \n",
    "            # Use original_id for sequences_from_updated.csv\n",
    "            if input_file == 'sequences_from_updated.csv':\n",
    "                ensembl_id = id_mapping.get(ensembl_id, ensembl_id)\n",
    "\n",
    "            result = scan_for_high_similarity(ensembl_id, sequence)\n",
    "            print(result)\n",
    "\n",
    "            # break  # Break after the first entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be17b5-5c8c-4417-b265-07fc5d74ee9a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### DOES ALIGNMENTS, BUT OUTPUTS THE WRONG IDS FOR UPDATED DATA. USES UPDATED IDS. ALSO DOESN'T USE BEST ALIGNMENTS. NO IDEA WHAT HAPPENED\n",
    "import csv\n",
    "from Bio import Align\n",
    "import sys\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "def load_id_mapping(mapping_file):\n",
    "    id_map = {}\n",
    "    with open(mapping_file, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            id_map[row['updated_id']] = row['original_id']\n",
    "    return id_map\n",
    "\n",
    "def scan_for_high_similarity(ensembl_id, sequence, csvwriter):\n",
    "    aligner = Align.PairwiseAligner()\n",
    "    aligner.mode = 'local'\n",
    "    aligner.match_score = 2\n",
    "    aligner.mismatch_score = -3\n",
    "    aligner.open_gap_score = -5\n",
    "    aligner.extend_gap_score = -2\n",
    "\n",
    "    alignments = aligner.align(sequence, target_sequence)\n",
    "    best_alignment = alignments[0] if alignments else None\n",
    "    \n",
    "    if best_alignment:\n",
    "        aligned_seq = best_alignment.target\n",
    "        aligned_target = best_alignment.query\n",
    "        aligned_positions = best_alignment.aligned\n",
    "        gene_aligned = display_alignment(sequence, target_sequence, aligned_positions)\n",
    "        print(f\"{ensembl_id} {gene_aligned}\")\n",
    "        # csvwriter.writerow([ensembl_id, gene_aligned])\n",
    "\n",
    "def display_alignment(sequence, target_sequence, alignment_positions):\n",
    "    gene_aligned = \"\"\n",
    "    gene_alignments = alignment_positions[0]\n",
    "    for gene_range in gene_alignments:\n",
    "        gene_aligned += sequence[gene_range[0]:gene_range[1]]\n",
    "    return gene_aligned\n",
    "\n",
    "id_mapping = load_id_mapping('updated_ids.csv')\n",
    "input_files = ['sequences.csv', 'sequences_from_updated.csv']\n",
    "# input_files = ['sequences_from_updated.csv', 'sequences.csv']\n",
    "target_sequence = \"ATCTCCTAATATGAATCCTAT\"\n",
    "\n",
    "\n",
    "with open('gene_alignments.csv', 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(['ensembl_id', 'gene_aligned'])  # Write header\n",
    "\n",
    "    for input_file in input_files:\n",
    "        with open(input_file, 'r') as infile:\n",
    "            reader = csv.DictReader(infile)\n",
    "            \n",
    "            for row in reader:\n",
    "                ensembl_id = row['ensemble_id']\n",
    "                sequence = row['sequence']\n",
    "                \n",
    "                if input_file == 'sequences_from_updated.csv':\n",
    "                    ensembl_id = id_mapping.get(ensembl_id, ensembl_id)\n",
    "\n",
    "                scan_for_high_similarity(ensembl_id, sequence, csvwriter)\n",
    "                # break  # Break after the first entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78ad7fda-504e-4e2e-be06-950b81bfecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('gene_alignments.csv')\n",
    "df['target_rna'] = df['gene_aligned'].apply(lambda seq: seq.replace('T', 'U'))\n",
    "df.to_csv('gene_alignments2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05d588-a30a-4b09-8b20-b11d54e5eaa8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ALIGNMENTS NCBI all results\n",
    "import requests\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "\n",
    "def get_entrez_id_from_ensembl(ensembl_id):\n",
    "    url = f\"https://rest.ensembl.org/xrefs/id/{ensembl_id}?external_db=EntrezGene\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            return data[0][\"primary_id\"]  # Return the Entrez Gene ID\n",
    "    return None\n",
    "\n",
    "ensembl_id = \"ENSG00000051382\"\n",
    "entrez_id = get_entrez_id_from_ensembl(ensembl_id)\n",
    "\n",
    "if entrez_id:\n",
    "    print(f\"Fetched Entrez ID for {ensembl_id}: {entrez_id}\")\n",
    "    target_sequence = \"ATCTCCTAATATGAATCCTAT\"\n",
    "\n",
    "    print(f\"Running BLAST using Entrez ID {entrez_id} as the subject...\")\n",
    "\n",
    "    # Add taxonomic filter for Homo sapiens (taxid:9606)\n",
    "    # Set expect threshold and other relevant parameters for a short sequence\n",
    "    result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", target_sequence, entrez_query=f\"{entrez_id} AND txid9606[ORGN]\", expect=10, short_query=True)\n",
    "\n",
    "    with open(\"blast_result.xml\", \"w\") as out_handle:\n",
    "        out_handle.write(result_handle.read())\n",
    "\n",
    "    with open(\"blast_result.xml\") as result_handle:\n",
    "        blast_record = NCBIXML.read(result_handle)\n",
    "\n",
    "    for alignment in blast_record.alignments:\n",
    "        print(f\"Alignment: {alignment.title}\")\n",
    "        for hsp in alignment.hsps:\n",
    "            print(f\"Query/Match/Subject:\\n{hsp.query}\\n{hsp.match}\\n{hsp.sbjct}\")\n",
    "            print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "else:\n",
    "    print(f\"Could not fetch the Entrez ID for Ensembl ID {ensembl_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b9d615-daf1-4ff9-a330-24ab93fd5e70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ALIGNMENTS NCBI\n",
    "import requests\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "\n",
    "def get_entrez_id_from_ensembl(ensembl_id):\n",
    "    url = f\"https://rest.ensembl.org/xrefs/id/{ensembl_id}?external_db=EntrezGene\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            return data[0][\"primary_id\"]  # Return the Entrez Gene ID\n",
    "    return None\n",
    "\n",
    "ensembl_id = \"ENSG00000051382\"\n",
    "entrez_id = get_entrez_id_from_ensembl(ensembl_id)\n",
    "\n",
    "if entrez_id:\n",
    "    print(f\"Fetched Entrez ID for {ensembl_id}: {entrez_id}\")\n",
    "    target_sequence = \"ATCTCCTAATATGAATCCTAT\"\n",
    "\n",
    "    print(f\"Running BLAST using Entrez ID {entrez_id} as the subject...\")\n",
    "\n",
    "    result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", target_sequence, entrez_query=f\"{entrez_id} AND txid9606[ORGN]\", expect=1, short_query=True)\n",
    "\n",
    "    with open(\"blast_result.xml\", \"w\") as out_handle:\n",
    "        out_handle.write(result_handle.read())\n",
    "\n",
    "    with open(\"blast_result.xml\") as result_handle:\n",
    "        blast_record = NCBIXML.read(result_handle)\n",
    "\n",
    "    # Initialize variables to store the highest scoring alignment and HSP\n",
    "    best_hsp = None\n",
    "    best_alignment = None\n",
    "    highest_score = 0\n",
    "    print(\"ncbi data rcvd\")\n",
    "    # Iterate through all alignments and HSPs\n",
    "    for alignment in blast_record.alignments:\n",
    "        for hsp in alignment.hsps:\n",
    "            if hsp.score > highest_score:\n",
    "                highest_score = hsp.score\n",
    "                best_hsp = hsp\n",
    "                best_alignment = alignment\n",
    "\n",
    "    # Print the alignment with the highest score\n",
    "    if best_hsp and best_alignment:\n",
    "        print(f\"Best Alignment: {best_alignment.title}\")\n",
    "        print(f\"Highest Score: {best_hsp.score}\")\n",
    "        print(f\"Query/Match/Subject:\\n{best_hsp.query}\\n{best_hsp.match}\\n{best_hsp.sbjct}\")\n",
    "        print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "else:\n",
    "    print(f\"Could not fetch the Entrez ID for Ensembl ID {ensembl_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada45ac-fb48-4843-a1a8-f1ddb2c0324b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ALIGNMENTS NCBI\n",
    "import requests\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "\n",
    "def get_entrez_id_from_ensembl(ensembl_id):\n",
    "    url = f\"https://rest.ensembl.org/xrefs/id/{ensembl_id}?external_db=EntrezGene\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data:\n",
    "            return data[0][\"primary_id\"]  # Return the Entrez Gene ID\n",
    "    return None\n",
    "\n",
    "ensembl_id = \"ENSG00000051382\"\n",
    "entrez_id = get_entrez_id_from_ensembl(ensembl_id)\n",
    "\n",
    "if entrez_id:\n",
    "    print(f\"Fetched Entrez ID for {ensembl_id}: {entrez_id}\")\n",
    "    target_sequence = \"ATCTCCTAATATGAATCCTAT\"\n",
    "\n",
    "    print(f\"Running BLAST using Entrez ID {entrez_id} and limiting to Homo sapiens...\")\n",
    "\n",
    "    # Run BLAST using the Entrez ID and limiting to Homo sapiens (taxid:9606)\n",
    "    result_handle = NCBIWWW.qblast(\n",
    "        \"blastn\", \n",
    "        \"nt\", \n",
    "        target_sequence, \n",
    "        entrez_query=f\"txid9606[ORGN]\",  # Specify the organism (Homo sapiens, taxid:9606)\n",
    "        entrez_query_filter=entrez_id  # Use only Entrez ID 5291\n",
    "    )\n",
    "\n",
    "    with open(\"blast_result.xml\", \"w\") as out_handle:\n",
    "        out_handle.write(result_handle.read())\n",
    "\n",
    "    with open(\"blast_result.xml\") as result_handle:\n",
    "        blast_record = NCBIXML.read(result_handle)\n",
    "\n",
    "    # Initialize variables to store the highest scoring alignment and HSP\n",
    "    best_hsp = None\n",
    "    best_alignment = None\n",
    "    highest_score = 0\n",
    "\n",
    "    # Iterate through all alignments and HSPs\n",
    "    for alignment in blast_record.alignments:\n",
    "        for hsp in alignment.hsps:\n",
    "            if hsp.score > highest_score:\n",
    "                highest_score = hsp.score\n",
    "                best_hsp = hsp\n",
    "                best_alignment = alignment\n",
    "\n",
    "    # Print the alignment with the highest score\n",
    "    if best_hsp and best_alignment:\n",
    "        print(f\"Best Alignment: {best_alignment.title}\")\n",
    "        print(f\"Highest Score: {best_hsp.score}\")\n",
    "        print(f\"Query/Match/Subject:\\n{best_hsp.query}\\n{best_hsp.match}\\n{best_hsp.sbjct}\")\n",
    "        print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "else:\n",
    "    print(f\"Could not fetch the Entrez ID for Ensembl ID {ensembl_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c406c532-513a-4949-a57c-4455c219b1d4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences have been written to sequences_from_updated.csv\n"
     ]
    }
   ],
   "source": [
    "# PREFETCH SEQUENCES FROM UPDATED IDS\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "# Define the input and output file names\n",
    "input_ids_file = 'updated_ids.csv'  # This is the updated IDs file\n",
    "output_file = 'sequences_from_updated.csv'  # New output file for sequences\n",
    "\n",
    "# Step 1: Read the updated Ensembl IDs from updated_ids.csv\n",
    "updated_ensembl_ids = []\n",
    "\n",
    "with open(input_ids_file, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        updated_id = row['updated_id']\n",
    "        updated_ensembl_ids.append(updated_id)\n",
    "\n",
    "# Step 2: Divide updated Ensembl IDs into batches of 50\n",
    "batch_size = 50\n",
    "batches = [updated_ensembl_ids[i:i + batch_size] for i in range(0, len(updated_ensembl_ids), batch_size)]\n",
    "\n",
    "# Step 3: Fetch sequences and write to a new CSV\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(['ensembl_id', 'sequence'])  # Write header\n",
    "\n",
    "    for batch in batches:\n",
    "        # Prepare the request to the Ensembl REST API\n",
    "        server = \"https://rest.ensembl.org\"\n",
    "        endpoint = \"/sequence/id\"\n",
    "        headers = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\"}\n",
    "        data = {\"ids\": batch}\n",
    "\n",
    "        # Make the POST request\n",
    "        response = requests.post(server + endpoint, headers=headers, json=data)\n",
    "\n",
    "        if not response.ok:\n",
    "            print(f\"Error fetching sequences for batch: {batch}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "            response.raise_for_status()\n",
    "\n",
    "        # Parse the JSON response\n",
    "        sequences = response.json()\n",
    "\n",
    "        # Write each sequence to the CSV file\n",
    "        for item in sequences:\n",
    "            ensembl_id = item['id']\n",
    "            sequence = item['seq']\n",
    "            csvwriter.writerow([ensembl_id, sequence])\n",
    "\n",
    "print(f\"Sequences have been written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d1b201-0223-4434-9a29-20b8678e581f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Ensembl ID: ENSG00000291237\n"
     ]
    }
   ],
   "source": [
    "# TESTING: COLLECTS MISSING SEQUENCES USING SELENIUM\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re  # Import regex for extracting the new ID\n",
    "\n",
    "os.environ['MOZ_HEADLESS'] = '1'\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "service = Service('/data/home/mrichte3/.local/bin/geckodriver')\n",
    "\n",
    "driver = webdriver.Firefox(service=service, options=options)\n",
    "\n",
    "# Navigate to the Ensembl website\n",
    "driver.get(\"https://useast.ensembl.org/index.html\")\n",
    "\n",
    "time.sleep(2)  # Allow the page to load\n",
    "\n",
    "# Find the search input box using XPath and enter the Ensembl ID\n",
    "search_box = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div/div[1]/div[1]/div[1]/div[2]/div/form/fieldset/div[3]/div[1]/div/input[2]\")\n",
    "ensembl_id = \"ENSG00000112096\"\n",
    "search_box.send_keys(ensembl_id)\n",
    "\n",
    "# Find and click the search button using XPath\n",
    "search_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div/div[1]/div[1]/div[1]/div[2]/div/form/fieldset/div[3]/div[1]/input\")\n",
    "search_button.click()\n",
    "\n",
    "time.sleep(5)  # Wait for the search results page to load\n",
    "\n",
    "# Look for the new identifier in the specified XPath\n",
    "try:\n",
    "    result = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div/div[2]/div[2]/div[4]/div/div/div[2]/div/div/div[3]/div[2]/div[1]/div[2]/div/div[1]/div/div/div/div[3]\").text\n",
    "    \n",
    "    # Use regex to extract all Ensembl IDs (first and second)\n",
    "    ids = re.findall(r'ENSG\\d+', result)\n",
    "    \n",
    "    if len(ids) > 1:\n",
    "        new_id = ids[1]  # Capture the second occurrence\n",
    "        print(f\"New Ensembl ID: {new_id}\")\n",
    "    else:\n",
    "        print(f\"Could not find the second Ensembl ID in the result.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error or no new identifier found: {e}\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a472755-65f0-48da-b027-b0a8d92d911e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# COLLECTS MISSING SEQUENCES, BUT ERRORS OUT\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "input_file = '6048D_rawCounts.txt'\n",
    "sequences_file = 'sequences.csv'\n",
    "output_file = 'sequences_fixed.csv'\n",
    "\n",
    "ensembl_ids = []\n",
    "with open(input_file, 'r') as f:\n",
    "    header = f.readline()\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            parts = line.strip().split()\n",
    "            if parts:\n",
    "                ensembl_id = parts[0]\n",
    "                ensembl_ids.append(ensembl_id)\n",
    "\n",
    "existing_sequences = {}\n",
    "with open(sequences_file, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        if len(row) == 2:\n",
    "            ensembl_id, sequence = row\n",
    "            existing_sequences[ensembl_id] = sequence\n",
    "\n",
    "missing_ids = [ensembl_id for ensembl_id in ensembl_ids if ensembl_id not in existing_sequences]\n",
    "\n",
    "os.environ['MOZ_HEADLESS'] = '1'\n",
    "options = Options()\n",
    "options.headless = True\n",
    "service = Service('/data/home/mrichte3/.local/bin/geckodriver')\n",
    "driver = webdriver.Firefox(service=service, options=options)\n",
    "\n",
    "def fetch_updated_ensembl_id(ensembl_id):\n",
    "    driver.get(\"https://useast.ensembl.org/index.html\")\n",
    "    time.sleep(2)\n",
    "    search_box = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div/div[1]/div[1]/div[1]/div[2]/div/form/fieldset/div[3]/div[1]/div/input[2]\")\n",
    "    search_box.send_keys(ensembl_id)\n",
    "    search_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div/div[1]/div[1]/div[1]/div[2]/div/form/fieldset/div[3]/div[1]/input\")\n",
    "    search_button.click()\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        result = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div/div[2]/div[2]/div[4]/div/div/div[2]/div/div/div[3]/div[2]/div[1]/div[2]/div/div[1]/div/div/div/div[3]\").text\n",
    "        ids = re.findall(r'ENSG\\d+', result)\n",
    "        if len(ids) > 1:\n",
    "            new_id = ids[1]\n",
    "            print(f\"Updated ID found: {new_id} for {ensembl_id}\")\n",
    "            return new_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching ID for {ensembl_id}: {e}\")\n",
    "    return None\n",
    "\n",
    "updated_ids = []\n",
    "for missing_id in missing_ids:\n",
    "    updated_id = fetch_updated_ensembl_id(missing_id)\n",
    "    if updated_id:\n",
    "        updated_ids.append({'original_id': missing_id, 'updated_id': updated_id})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame(updated_ids)\n",
    "# df.to_csv('updated_ids.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f36a22f-3f63-4091-9dbb-6ab94193c28d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# COLLECTS MISSING SEQUENCES 2, STARTING FROM ABOVE DFS\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming these lists are already available in memory\n",
    "# updated_ids = [{'original_id': '...', 'updated_id': '...'}, ...]\n",
    "# missing_ids = ['...', '...']\n",
    "last_processed_id = 'ENSG00000281167'\n",
    "skip = True\n",
    "\n",
    "os.environ['MOZ_HEADLESS'] = '1'\n",
    "options = Options()\n",
    "options.headless = True\n",
    "service = Service('/data/home/mrichte3/.local/bin/geckodriver')\n",
    "driver = webdriver.Firefox(service=service, options=options)\n",
    "\n",
    "def fetch_updated_ensembl_id(ensembl_id):\n",
    "    try:\n",
    "        driver.get(\"https://useast.ensembl.org/index.html\")\n",
    "        time.sleep(2)\n",
    "        search_box = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div/div[1]/div[1]/div[1]/div[2]/div/form/fieldset/div[3]/div[1]/div/input[2]\")\n",
    "        search_box.send_keys(ensembl_id)\n",
    "        search_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div/div[1]/div[1]/div[1]/div[2]/div/form/fieldset/div[3]/div[1]/input\")\n",
    "        search_button.click()\n",
    "        time.sleep(5)\n",
    "        \n",
    "        result = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div/div[2]/div[2]/div[4]/div/div/div[2]/div/div/div[3]/div[2]/div[1]/div[2]/div/div[1]/div/div/div/div[3]\").text\n",
    "        ids = re.findall(r'ENSG\\d+', result)\n",
    "        \n",
    "        if len(ids) > 1:\n",
    "            new_id = ids[1]\n",
    "            print(f\"Updated ID found: {new_id} for {ensembl_id}\")\n",
    "            return new_id\n",
    "        else:\n",
    "            print(f\"No updated ID found for {ensembl_id}.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching ID for {ensembl_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "found_last_id = False  # To track when we should start processing\n",
    "\n",
    "for missing_id in missing_ids:\n",
    "    if missing_id == last_processed_id:\n",
    "        found_last_id = True\n",
    "        continue  # Skip the last processed ID\n",
    "    \n",
    "    if not found_last_id:\n",
    "        continue  # Skip IDs until we find the last processed one\n",
    "\n",
    "    updated_id = fetch_updated_ensembl_id(missing_id)\n",
    "    if updated_id:\n",
    "        updated_ids.append({'original_id': missing_id, 'updated_id': updated_id})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame(updated_ids)\n",
    "df.to_csv('updated_ids.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7976154-802d-4da1-8cdf-560ce65c422d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
